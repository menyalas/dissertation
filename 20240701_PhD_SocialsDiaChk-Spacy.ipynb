{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Letter Chunk Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1023 entries, 0 to 1022\n",
      "Data columns (total 31 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   docID-AT          1023 non-null   int64  \n",
      " 1   docid             1023 non-null   object \n",
      " 2   docyear           1023 non-null   int64  \n",
      " 3   docmonth          0 non-null      float64\n",
      " 4   authorName        1023 non-null   object \n",
      " 5   docauthorid       1023 non-null   object \n",
      " 6   authorLocation    1023 non-null   object \n",
      " 7   authorGender      1023 non-null   object \n",
      " 8   nationalOrigin    921 non-null    object \n",
      " 9   irish             921 non-null    object \n",
      " 10  otherUK           921 non-null    object \n",
      " 11  relMin            1023 non-null   bool   \n",
      " 12  catholic          1023 non-null   bool   \n",
      " 13  otherChristian    1023 non-null   bool   \n",
      " 14  U                 1023 non-null   bool   \n",
      " 15  M                 1023 non-null   bool   \n",
      " 16  S                 1023 non-null   bool   \n",
      " 17  F                 1023 non-null   bool   \n",
      " 18  L                 1023 non-null   bool   \n",
      " 19  text              1023 non-null   object \n",
      " 20  sequence          1023 non-null   int64  \n",
      " 21  totalTokens       1023 non-null   int64  \n",
      " 22  uniqueTokens      1023 non-null   int64  \n",
      " 23  lexicalDiversity  1023 non-null   float64\n",
      " 24  scoreNeg          1023 non-null   float64\n",
      " 25  scoreNeu          1023 non-null   float64\n",
      " 26  scorePos          1023 non-null   float64\n",
      " 27  scoreCom          1023 non-null   float64\n",
      " 28  chunks            1023 non-null   int64  \n",
      " 29  position          1023 non-null   float64\n",
      " 30  topicNumber       1023 non-null   int64  \n",
      "dtypes: bool(8), float64(7), int64(7), object(9)\n",
      "memory usage: 199.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Sentence Data\n",
    "df = pd.read_csv(\"20240701_PhD_Data4NER-DiaChk.csv\", index_col=0) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the NER of various models on the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next few cells are run multiple times to check performance of various pre-trained models. \n",
    "# Do not run the this cell until after the first pass\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I started with 0 and checked \n",
    "chunk = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disappointed ie our trip for the time present. Go for a walky met Mrs Davey Dicks school master he is most polide. Dick has to be correcded for not taking off his hat. Papan wlo boasts that he has not eaten food for three day. he has eved by sctioon think he brandy is better this evening Jan 17 I surns out a nice cool morning 0 Pap who finds he is munch wanted at Glynde Starts. Think he Stirling stow make the mtdings bing Custard and Blinbarl stewed which Polly and I pad walked to a garden not for from Dicks school. We came nom i different wy and loager I make myself a newt hair bow and follow me boy of Bink alon Polly had given me. It is co cold that I am able to put on my winter dress We go for a nise walk little life bacd Hanson trap Orinen Hansone Beil and sun dades Mr Mrs Harvey in a good buggy and pair. The looks so frest and prett go to Mrs Games to lee her get honer Aunstand taking the hony He has a get Green beil and red woollst gloves the bees are all on his back. The home is rater too old and a great deal to wastt I feel so very fired as it is so cold leep on the sofa. Jan 13 I feel ery sull and have nothing to do sil and listen to Polls and Mamas converiato. after some tim Pole for a wall and 1 then to the store let the papers with the Euglish hews the trince Wales has been ill with slyphod eure almost dead but is now getteng. better.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place narratives into a list representing the corpus\n",
    "texts = df.text.values.tolist()\n",
    "texts[chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mentions: 14 \n",
      "\n",
      "{'Davey Dicks': 1, 'Dick': 1, 'surns': 1, 'Polly': 1, 'Hanson': 1, 'Hansone Beil': 1, 'Mrs Harvey': 1, 'prett': 1, 'Mrs Games': 1, 'lee': 1, 'red woollst': 1, 'sil': 1, 'Mamas converiato': 1, 'getteng': 1} \n",
      "\n",
      "Number of individuals: 14 \n",
      "\n",
      "Individuals: {'Mrs Games', 'Polly', 'lee', 'Dick', 'surns', 'Davey Dicks', 'prett', 'sil', 'getteng', 'Hansone Beil', 'Hanson', 'Mamas converiato', 'red woollst', 'Mrs Harvey'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on first item\n",
    "item = texts[chunk]\n",
    "\n",
    "# Run the language model on the 1st narrative\n",
    "narrative = nlp(item)\n",
    "\n",
    "# Find the mentions to people in the narrative\n",
    "\n",
    "for ent in narrative.ents:\n",
    "\n",
    "    mentions = [ent.text for ent in narrative.ents if ent.label_ == 'PERSON']\n",
    "        \n",
    "    counts = {}\n",
    "    for person in mentions:\n",
    "        counts[person] = counts.get(person, 0) + 1\n",
    "    \n",
    "    individuals = set(mentions)\n",
    "    \n",
    "print(\"Number of mentions:\", len(mentions), \"\\n\")\n",
    "print(counts, \"\\n\")    \n",
    "print(\"Number of individuals:\", len(individuals), \"\\n\")\n",
    "print(\"Individuals:\", individuals, \"\\n\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">disappointed ie our trip for the time present. Go for a walky met Mrs \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Davey Dicks\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " school master he is most polide. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Dick\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has to be correcded for not taking off his hat. Papan wlo boasts that he has not eaten food for three day. he has eved by sctioon think he brandy is better this evening Jan 17 I \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    surns\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " out a nice cool morning 0 Pap who finds he is munch wanted at Glynde Starts. Think he Stirling stow make the mtdings bing Custard and Blinbarl stewed which \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Polly\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and I pad walked to a garden not for from Dicks school. We came nom i different wy and loager I make myself a newt hair bow and follow me boy of Bink alon Polly had given me. It is co cold that I am able to put on my winter dress We go for a nise walk little life bacd \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hanson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " trap Orinen \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hansone Beil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and sun dades Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mrs Harvey\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " in a good buggy and pair. The looks so frest and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    prett\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " go to \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mrs Games\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    lee\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " her get honer Aunstand taking the hony He has a get Green beil and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    red woollst\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " gloves the bees are all on his back. The home is rater too old and a great deal to wastt I feel so very fired as it is so cold leep on the sofa. Jan 13 I feel ery sull and have nothing to do \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    sil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and listen to Polls and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mamas converiato\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". after some tim Pole for a wall and 1 then to the store let the papers with the Euglish hews the trince Wales has been ill with slyphod eure almost dead but is now \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    getteng\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". better.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = texts[chunk]\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"ent\", options = {\"ents\": [\"PERSON\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity extraction for the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "1023\n",
      "1023\n",
      "8\n",
      "6\n",
      "{'Mrs Roberts': 3, 'Tom': 1, 'Hiern': 1, 'Worrier': 1, 'Jeff Miller': 1, 'Jimmy Roberts': 1}\n"
     ]
    }
   ],
   "source": [
    "mentsTot = [] \n",
    "mentsDis = []\n",
    "indsTot = []\n",
    "\n",
    "for item in texts:\n",
    "\n",
    "# Run the language model on the 1st narrative\n",
    "    narrative = nlp(item)\n",
    "\n",
    "# Find the mentions to people in the narrative\n",
    "\n",
    "    for ent in narrative.ents:\n",
    "\n",
    "        mentions = [ent.text for ent in narrative.ents if ent.label_ == 'PERSON']\n",
    "        \n",
    "        counts = {}\n",
    "        for person in mentions:\n",
    "            counts[person] = counts.get(person, 0) + 1\n",
    "    \n",
    "        individuals = set(mentions)\n",
    "    \n",
    "    mentsTot.append(len(mentions))\n",
    "    mentsDis.append(counts)\n",
    "    indsTot.append(len(individuals))\n",
    "    \n",
    "                   \n",
    "print(len(mentsTot)) \n",
    "print(len(indsTot))\n",
    "print(len(mentsDis))\n",
    "\n",
    "print(mentsTot[0]) \n",
    "print(indsTot[0])\n",
    "print(mentsDis[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for 1st person singular pronounds, subjective and objective only per Tackman, A. M., Sbarra, D. A., Carey, A. L., Donnellan, M. B., Horn, A. B., Holtzman, N. S., Edwards, T. S., Pennebaker, J. W., & Mehl, M. R. (2019). Depression, Negative Emotionality, and Self-Referential Language: A Multi-Lab, Multi-Measure, and Multi-Language-Task Research Synthesis. Journal of Personality and Social Psychology, 116(5), 817–834. https://doi.org/10.1037/pspp0000187.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I ', \"I'm \", \"I've \", \"I'll \", \"I'd \", ' me ', 'Me ', ' myself ', 'Myself ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounAll = [\"I \", \n",
    "               \"I'm \", \n",
    "               \"I've \", \n",
    "               \"I'll \", \n",
    "               \"I'd \", \n",
    "               \" me \", \n",
    "               \"Me \", \n",
    "               \" myself \", \n",
    "               \"Myself \"]\n",
    "pronounAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I ', \"I'm \", \"I've \", \"I'll \", \"I'd \"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounSub = [\"I \", \"I'm \", \"I've \", \"I'll \", \"I'd \"]\n",
    "pronounSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' me ', 'Me ', ' myself ', 'Myself ']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounObj = [\" me \", \n",
    "               \"Me \", \n",
    "               \" myself \", \n",
    "               \"Myself \"]\n",
    "pronounObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts = [x.lower() for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'disappointed ie our trip for the time present. Go for a walky met Mrs Davey Dicks school master he is most polide. Dick has to be correcded for not taking off his hat. Papan wlo boasts that he has not eaten food for three day. he has eved by sctioon think he brandy is better this evening Jan 17 I surns out a nice cool morning 0 Pap who finds he is munch wanted at Glynde Starts. Think he Stirling stow make the mtdings bing Custard and Blinbarl stewed which Polly and I pad walked to a garden not for from Dicks school. We came nom i different wy and loager I make myself a newt hair bow and follow me boy of Bink alon Polly had given me. It is co cold that I am able to put on my winter dress We go for a nise walk little life bacd Hanson trap Orinen Hansone Beil and sun dades Mr Mrs Harvey in a good buggy and pair. The looks so frest and prett go to Mrs Games to lee her get honer Aunstand taking the hony He has a get Green beil and red woollst gloves the bees are all on his back. The home is rater too old and a great deal to wastt I feel so very fired as it is so cold leep on the sofa. Jan 13 I feel ery sull and have nothing to do sil and listen to Polls and Mamas converiato. after some tim Pole for a wall and 1 then to the store let the papers with the Euglish hews the trince Wales has been ill with slyphod eure almost dead but is now getteng. better.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Subjective\n",
    "\n",
    "Count = 0\n",
    "\n",
    "for i in pronounSub:\n",
    "    Count = texts[chunk].count(i) + Count\n",
    "\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Objective\n",
    "\n",
    "Count = 0\n",
    "\n",
    "for i in pronounObj:\n",
    "    Count = texts[chunk].count(i) + Count\n",
    "\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# All pronouns\n",
    "\n",
    "Count = 0\n",
    "\n",
    "for i in pronounAll:\n",
    "    Count = texts[chunk].count(i) + Count\n",
    "\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run on all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "[10, 8, 8, 8, 10, 10, 4, 7, 10]\n"
     ]
    }
   ],
   "source": [
    "# Now the rest\n",
    "\n",
    "fppAll_Ct = []\n",
    "\n",
    "for item in texts:\n",
    "    Count = 0\n",
    "    for i in pronounAll:\n",
    "        #print(texts[0].count(i))\n",
    "        Count = item.count(i) + Count\n",
    "    \n",
    "    fppAll_Ct.append(Count)\n",
    "\n",
    "print(len(fppAll_Ct))\n",
    "print(fppAll_Ct[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "[7, 6, 7, 6, 10, 8, 1, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "# Now just subjective pronouns\n",
    "\n",
    "fppSub_Ct = []\n",
    "\n",
    "for item in texts:\n",
    "    Count = 0\n",
    "    for i in pronounSub:\n",
    "        #print(texts[0].count(i))\n",
    "        Count = item.count(i) + Count\n",
    "    \n",
    "    fppSub_Ct.append(Count)\n",
    "\n",
    "print(len(fppSub_Ct))\n",
    "print(fppSub_Ct[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "[3, 2, 1, 2, 0, 2, 3, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# Now just subjective pronouns\n",
    "\n",
    "fppObj_Ct = []\n",
    "\n",
    "for item in texts:\n",
    "    Count = 0\n",
    "    for i in pronounObj:\n",
    "        #print(texts[0].count(i))\n",
    "        Count = item.count(i) + Count\n",
    "    \n",
    "    fppObj_Ct.append(Count)\n",
    "\n",
    "print(len(fppObj_Ct))\n",
    "print(fppObj_Ct[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new variables to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1023 entries, 0 to 1022\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   docID-AT          1023 non-null   int64  \n",
      " 1   docid             1023 non-null   object \n",
      " 2   docyear           1023 non-null   int64  \n",
      " 3   docmonth          0 non-null      float64\n",
      " 4   authorName        1023 non-null   object \n",
      " 5   docauthorid       1023 non-null   object \n",
      " 6   authorLocation    1023 non-null   object \n",
      " 7   authorGender      1023 non-null   object \n",
      " 8   nationalOrigin    921 non-null    object \n",
      " 9   irish             921 non-null    object \n",
      " 10  otherUK           921 non-null    object \n",
      " 11  relMin            1023 non-null   bool   \n",
      " 12  catholic          1023 non-null   bool   \n",
      " 13  otherChristian    1023 non-null   bool   \n",
      " 14  U                 1023 non-null   bool   \n",
      " 15  M                 1023 non-null   bool   \n",
      " 16  S                 1023 non-null   bool   \n",
      " 17  F                 1023 non-null   bool   \n",
      " 18  L                 1023 non-null   bool   \n",
      " 19  text              1023 non-null   object \n",
      " 20  sequence          1023 non-null   int64  \n",
      " 21  totalTokens       1023 non-null   int64  \n",
      " 22  uniqueTokens      1023 non-null   int64  \n",
      " 23  lexicalDiversity  1023 non-null   float64\n",
      " 24  scoreNeg          1023 non-null   float64\n",
      " 25  scoreNeu          1023 non-null   float64\n",
      " 26  scorePos          1023 non-null   float64\n",
      " 27  scoreCom          1023 non-null   float64\n",
      " 28  chunks            1023 non-null   int64  \n",
      " 29  position          1023 non-null   float64\n",
      " 30  topicNumber       1023 non-null   int64  \n",
      " 31  mentsDis          1023 non-null   object \n",
      " 32  mentsTot          1023 non-null   int64  \n",
      " 33  indsTot           1023 non-null   int64  \n",
      " 34  fppAll_Ct         1023 non-null   int64  \n",
      " 35  fppSub_Ct         1023 non-null   int64  \n",
      " 36  fppObj_Ct         1023 non-null   int64  \n",
      "dtypes: bool(8), float64(7), int64(12), object(10)\n",
      "memory usage: 247.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df['mentsDis'] = [', '.join(x) for x in mentsDis]\n",
    "df['mentsTot'] = mentsTot\n",
    "df['indsTot'] = indsTot\n",
    "df['fppAll_Ct'] = fppAll_Ct\n",
    "df['fppSub_Ct'] = fppSub_Ct\n",
    "df['fppObj_Ct'] = fppObj_Ct\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID-AT</th>\n",
       "      <th>docid</th>\n",
       "      <th>docyear</th>\n",
       "      <th>docmonth</th>\n",
       "      <th>authorName</th>\n",
       "      <th>docauthorid</th>\n",
       "      <th>authorLocation</th>\n",
       "      <th>authorGender</th>\n",
       "      <th>nationalOrigin</th>\n",
       "      <th>irish</th>\n",
       "      <th>...</th>\n",
       "      <th>scoreCom</th>\n",
       "      <th>chunks</th>\n",
       "      <th>position</th>\n",
       "      <th>topicNumber</th>\n",
       "      <th>mentsDis</th>\n",
       "      <th>mentsTot</th>\n",
       "      <th>indsTot</th>\n",
       "      <th>fppAll_Ct</th>\n",
       "      <th>fppSub_Ct</th>\n",
       "      <th>fppObj_Ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>D0002</td>\n",
       "      <td>1883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anne F. Richards</td>\n",
       "      <td>D0002</td>\n",
       "      <td>Australia</td>\n",
       "      <td>F</td>\n",
       "      <td>English</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379767</td>\n",
       "      <td>447</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>8</td>\n",
       "      <td>Mrs Roberts, Tom, Hiern, Worrier, Jeff Miller,...</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>D0002</td>\n",
       "      <td>1883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anne F. Richards</td>\n",
       "      <td>D0002</td>\n",
       "      <td>Australia</td>\n",
       "      <td>F</td>\n",
       "      <td>English</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058833</td>\n",
       "      <td>447</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>8</td>\n",
       "      <td>Jeff Miller, Jimmy Roberts, Mrs Roberts, Rober...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>D0002</td>\n",
       "      <td>1883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anne F. Richards</td>\n",
       "      <td>D0002</td>\n",
       "      <td>Australia</td>\n",
       "      <td>F</td>\n",
       "      <td>English</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137725</td>\n",
       "      <td>447</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>8</td>\n",
       "      <td>Frank, Tom, Charra, Brandy, Mrs Roberts, Weath...</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>D0002</td>\n",
       "      <td>1883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anne F. Richards</td>\n",
       "      <td>D0002</td>\n",
       "      <td>Australia</td>\n",
       "      <td>F</td>\n",
       "      <td>English</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216920</td>\n",
       "      <td>447</td>\n",
       "      <td>0.008949</td>\n",
       "      <td>8</td>\n",
       "      <td>Mrs Roberts, Weather, Albert Campbell, William...</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>D0002</td>\n",
       "      <td>1883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anne F. Richards</td>\n",
       "      <td>D0002</td>\n",
       "      <td>Australia</td>\n",
       "      <td>F</td>\n",
       "      <td>English</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371971</td>\n",
       "      <td>447</td>\n",
       "      <td>0.011186</td>\n",
       "      <td>8</td>\n",
       "      <td>Hoskin, Tom, Worrier, Frank, Hiern, Jeff Mille...</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   docID-AT  docid  docyear  docmonth        authorName docauthorid  \\\n",
       "0         1  D0002     1883       NaN  Anne F. Richards       D0002   \n",
       "1         2  D0002     1883       NaN  Anne F. Richards       D0002   \n",
       "2         3  D0002     1883       NaN  Anne F. Richards       D0002   \n",
       "3         4  D0002     1883       NaN  Anne F. Richards       D0002   \n",
       "4         5  D0002     1883       NaN  Anne F. Richards       D0002   \n",
       "\n",
       "  authorLocation authorGender nationalOrigin  irish  ...  scoreCom  chunks  \\\n",
       "0      Australia            F        English  False  ... -0.379767     447   \n",
       "1      Australia            F        English  False  ... -0.058833     447   \n",
       "2      Australia            F        English  False  ... -0.137725     447   \n",
       "3      Australia            F        English  False  ... -0.216920     447   \n",
       "4      Australia            F        English  False  ... -0.371971     447   \n",
       "\n",
       "   position  topicNumber                                           mentsDis  \\\n",
       "0  0.002237            8  Mrs Roberts, Tom, Hiern, Worrier, Jeff Miller,...   \n",
       "1  0.004474            8  Jeff Miller, Jimmy Roberts, Mrs Roberts, Rober...   \n",
       "2  0.006711            8  Frank, Tom, Charra, Brandy, Mrs Roberts, Weath...   \n",
       "3  0.008949            8  Mrs Roberts, Weather, Albert Campbell, William...   \n",
       "4  0.011186            8  Hoskin, Tom, Worrier, Frank, Hiern, Jeff Mille...   \n",
       "\n",
       "   mentsTot  indsTot  fppAll_Ct  fppSub_Ct fppObj_Ct  \n",
       "0         8        6         10          7         3  \n",
       "1        10        7          8          6         2  \n",
       "2         9        8          8          7         1  \n",
       "3        14       11          8          6         2  \n",
       "4        15        9         10         10         0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"20240701_PhD_FinalData-DiaryChk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
