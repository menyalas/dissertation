{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Letter Chunk Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2392 entries, 0 to 2391\n",
      "Data columns (total 31 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   docID-AT          2392 non-null   int64  \n",
      " 1   docid             2392 non-null   object \n",
      " 2   docyear           2392 non-null   int64  \n",
      " 3   docmonth          2364 non-null   float64\n",
      " 4   authorName        2177 non-null   object \n",
      " 5   docauthorid       2392 non-null   object \n",
      " 6   authorLocation    2392 non-null   object \n",
      " 7   authorGender      2392 non-null   object \n",
      " 8   nationalOrigin    2392 non-null   object \n",
      " 9   irish             2392 non-null   bool   \n",
      " 10  otherUK           2392 non-null   bool   \n",
      " 11  relMin            1065 non-null   object \n",
      " 12  catholic          1065 non-null   object \n",
      " 13  otherChristian    1065 non-null   object \n",
      " 14  U                 1253 non-null   object \n",
      " 15  M                 1276 non-null   object \n",
      " 16  S                 1245 non-null   object \n",
      " 17  F                 1243 non-null   object \n",
      " 18  L                 1266 non-null   object \n",
      " 19  text              2392 non-null   object \n",
      " 20  sequence          2392 non-null   int64  \n",
      " 21  totalTokens       2392 non-null   int64  \n",
      " 22  uniqueTokens      2392 non-null   int64  \n",
      " 23  lexicalDiversity  2392 non-null   float64\n",
      " 24  scoreNeg          2392 non-null   float64\n",
      " 25  scoreNeu          2392 non-null   float64\n",
      " 26  scorePos          2392 non-null   float64\n",
      " 27  scoreCom          2392 non-null   float64\n",
      " 28  chunks            2392 non-null   int64  \n",
      " 29  position          2392 non-null   float64\n",
      " 30  topicNumber       2392 non-null   int64  \n",
      "dtypes: bool(2), float64(7), int64(7), object(15)\n",
      "memory usage: 565.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Sentence Data\n",
    "df = pd.read_csv(\"20240611_PhD_Data4NER-LtrChk.csv\", index_col=0) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the NER of various models on the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next few cells are run multiple times to check performance of various pre-trained models. \n",
    "# Do not run the this cell until after the first pass\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I started with 0 and checked \n",
    "chunk = 1349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Jacques and Hays who greatly admired it. I wish they would order one of me. I had no idea that it would look so well; but it is hard work to draw with a needle so many groups out of your own head — 16 groups of flowers it took a group to every vandyke. I must take a rest now for the gay colors have made my eyes weak. I saw from my window at Weston the funeral of poor Col Richard Denison. The cemetry was just opposite our place at Weston. It was a pouring day but there was a great number of gentlemen came by train and carriages to the funeral. His death was very sudden. He had some small growth of flesh cut out of the nose that impeded his breathing and went out one cold day soon after before it was healed. Erysypelas set in and he died in a few hours. I see Dr Lister of BV is gone but have heard no particulars of his death. I saw Malcolm at Katey's last week but he looks very thin and pale and consumptive. Katey was much struck with Philip Wiggs appearance. I didn't see him but I like him much. Arthur Strickland had been there but I missed him also. I have met with a man who don't believe in a God nor in the bible nor in any first cause; Who thinks that death is death and that man is perfectly irrisponsible and in no degree superior to the animals. It was of no use arguing with him for he denied all evidence of God in the creation in revelation or in\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place narratives into a list representing the corpus\n",
    "texts = df.text.values.tolist()\n",
    "texts[chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mentions: 8 \n",
      "\n",
      "{'Jacques': 1, 'Hays': 1, 'Richard Denison': 1, 'Lister': 1, 'Malcolm': 1, 'Katey': 1, 'Philip Wiggs': 1, 'Arthur Strickland': 1} \n",
      "\n",
      "Number of individuals: 8 \n",
      "\n",
      "Individuals: {'Lister', 'Hays', 'Malcolm', 'Arthur Strickland', 'Katey', 'Richard Denison', 'Philip Wiggs', 'Jacques'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on first item\n",
    "item = texts[chunk]\n",
    "\n",
    "# Run the language model on the 1st narrative\n",
    "narrative = nlp(item)\n",
    "\n",
    "# Find the mentions to people in the narrative\n",
    "\n",
    "for ent in narrative.ents:\n",
    "\n",
    "    mentions = [ent.text for ent in narrative.ents if ent.label_ == 'PERSON']\n",
    "        \n",
    "    counts = {}\n",
    "    for person in mentions:\n",
    "        counts[person] = counts.get(person, 0) + 1\n",
    "    \n",
    "    individuals = set(mentions)\n",
    "    \n",
    "print(\"Number of mentions:\", len(mentions), \"\\n\")\n",
    "print(counts, \"\\n\")    \n",
    "print(\"Number of individuals:\", len(individuals), \"\\n\")\n",
    "print(\"Individuals:\", individuals, \"\\n\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't great because Darling Sister Justina is being broken into two entities and others aren't being found (e.g., Eugénie de Guérin, Sister Blandina). Let's highlight the labels for a sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jacques\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hays\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " who greatly admired it. I wish they would order one of me. I had no idea that it would look so well; but it is hard work to draw with a needle so many groups out of your own head — 16 groups of flowers it took a group to every vandyke. I must take a rest now for the gay colors have made my eyes weak. I saw from my window at Weston the funeral of poor Col \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Richard Denison\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". The cemetry was just opposite our place at Weston. It was a pouring day but there was a great number of gentlemen came by train and carriages to the funeral. His death was very sudden. He had some small growth of flesh cut out of the nose that impeded his breathing and went out one cold day soon after before it was healed. Erysypelas set in and he died in a few hours. I see Dr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Lister\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " of BV is gone but have heard no particulars of his death. I saw \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Malcolm\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " at Katey's last week but he looks very thin and pale and consumptive. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Katey\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was much struck with \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Philip Wiggs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " appearance. I didn't see him but I like him much. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Arthur Strickland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " had been there but I missed him also. I have met with a man who don't believe in a God nor in the bible nor in any first cause; Who thinks that death is death and that man is perfectly irrisponsible and in no degree superior to the animals. It was of no use arguing with him for he denied all evidence of God in the creation in revelation or in</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = texts[chunk]\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"ent\", options = {\"ents\": [\"PERSON\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, only one of the two references to Mother Josephine is being labeled. Let's see if changing the model will help. For chunk 567, this performed well. For chunk 1135, this model reasonably well. It mis-identifies Snow as a person but that is because the work is capitalised. For 1703, this model is perfect. There are no named people. For 2269, this model is perfect. For 284, this model performed perfectly. For 851, this model misses Agnes, The Colonel, Tiny man (a nickname so understandable). Also, possible the Jessie is a boat rather than a person. However, given the number of person references, this model does reasonably well. For 1419, this model performs almost perfectly. It attaches \"more than L10\" to Robert's name for some reason. For 1988, this model is perfect. For 100, Sister Justina is missed and the Sister without a personal name is tagged erratically (sometimes, sometimes not).\n",
    "\n",
    "I'm attempting to use the 19th century Word2Vec langauge model (Hosseini, 2021). The files come as Gensim export formats .model and .npy. First, I had to load these into Gensim and then export a .txt file that I could use with Spacy. See notebook 20240412_histLM.ipynb for that step. Once I had the .txt file, I followed the steps described at https://www.youtube.com/watch?v=JmLQedi80_Y and https://github.com/wjbmattingly/spacy_custom_vectors/blob/main/spacy_word_vecs.ipynb. I have decided not to train the model on my text but rather use the pre-trained model. These are reflected in the notebook spacy_word_vecs in my home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load(\"/Users/alaynemoody/spacy_custom_vectors-main/models/01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not seem necessary but keeping just in case.\n",
    "#nlp.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = texts[chunk]\n",
    "#doc = nlp(text)\n",
    "#displacy.render(doc, style=\"ent\", options = {\"ents\": [\"PERSON\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is even worse because it's not capturing Sister Justin or Sister M Louis and is mixing up places (e.g, Mt St Vincent and Steuvenville). Let's try the large Spacy model. \n",
    "\n",
    "For chunk 567, this performed well. For chunk 1135, this one performs ok. It does not misidentify Snow but it does miss Mr Young, which orthographically is clearly a person. For 1703, this model is also perfect. For 2269, this model performs badly, missing Captain Hale but misinterpreting Character (capitalized for emphasis) as a person. For 284, this model does ok, catching John but also tagging Sister, which refers to the narrator. For 851, this model misses Dunbar, Agnes, the Colonel, the Tiny man, Duponts and Henry -- plus it tags the potential boat. All in all, this model performs poorly. For 1419, this model performs poorly, missing multiple referenecs to Crtichlow and Mr Davies as well as to Cundall. For 1988, this model is perfect. For 100, this model misses Sister Justina and erratically tags Sister without a surname. Also incorrectly tages \"Vd\" and so I'm calling it a poor performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = texts[chunk]\n",
    "#doc = nlp(text)\n",
    "#displacy.render(doc, style=\"ent\", options = {\"ents\": [\"PERSON\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't much better as the two Mother Josephine references are being treated as two different people, and Sister Justina and Sister Blandina are being missed. I am going to re-run the cells above of some more texts to see how we go. After 10 trials, the medium and large models were tied. Doing another 10 with just those two, focusing on the authors that tripped up the models most: Segale, Moodie, Harris (more concerned with Sarah than Harris because she has more letters in the corpus (see counts below).\n",
    "\n",
    "Additional Runs: For 567, this performed poorly because it identified DeWitt and Davenport as people when in fact the quotes indicate it is a company (probably a publishing house). For 1135, this model performs best -- skipping Snow and finding Young. For 1703, again perfect. For 2269, this model is perfect. For 284, this model is perfect. For 851, this model misses the Colonel, Mrs H Traill and the Tiny man, so the same number as the medium model -- reasonably well. For 1419, this model performs perfectly. For 1988, this model is perfect. For 100, this model it better about not tagging the Sister-sans-surname references but it incorrectly tags \"Por amor.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df[df[\"docauthorid\"]==\"per0001043\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['docauthorname'][851]\n",
    "#df['docauthorname'][567]\n",
    "#len(df[df[\"docauthorname\"]==\"Moodie, Susannah Strickland, 1803-1885\"])\n",
    "#df['docID-AT'][df[\"docauthorname\"]==\"Moodie, Susannah Strickland, 1803-1885\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['docauthorname'][1419]\n",
    "#len(df[df[\"docauthorname\"]==\"Harris, Sarah Stretch, 1818-1897\"])\n",
    "#df['docID-AT'][df[\"docauthorname\"]==\"Harris, Sarah Stretch, 1818-1897\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['docauthorname'][1135]\n",
    "#len(df[df[\"docauthorname\"]==\"Harris, Critchlow, 1813-1899\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After ten trials it became clear that the histLM performed by far worse than the two Spacy models and so I dropped it before continuing on with the final ten trials. The medium sized model slightly outperformed the large model (score of 2.4 compared to 2.5) and so I have decided to proceed with this one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity extraction for the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392\n",
      "2392\n",
      "2392\n",
      "3\n",
      "3\n",
      "{'Isabella Moore': 1, 'Willie': 1, 'Bye Isabella Weir': 1}\n"
     ]
    }
   ],
   "source": [
    "mentsTot = [] \n",
    "mentsDis = []\n",
    "indsTot = []\n",
    "\n",
    "for item in texts:\n",
    "\n",
    "# Run the language model on the 1st narrative\n",
    "    narrative = nlp(item)\n",
    "\n",
    "# Find the mentions to people in the narrative\n",
    "\n",
    "    for ent in narrative.ents:\n",
    "\n",
    "        mentions = [ent.text for ent in narrative.ents if ent.label_ == 'PERSON']\n",
    "        \n",
    "        counts = {}\n",
    "        for person in mentions:\n",
    "            counts[person] = counts.get(person, 0) + 1\n",
    "    \n",
    "        individuals = set(mentions)\n",
    "    \n",
    "    mentsTot.append(len(mentions))\n",
    "    mentsDis.append(counts)\n",
    "    indsTot.append(len(individuals))\n",
    "    \n",
    "                   \n",
    "print(len(mentsTot)) \n",
    "print(len(indsTot))\n",
    "print(len(mentsDis))\n",
    "\n",
    "print(mentsTot[0]) \n",
    "print(indsTot[0])\n",
    "print(mentsDis[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for 1st person singular pronounds, subjective and objective only per Tackman, A. M., Sbarra, D. A., Carey, A. L., Donnellan, M. B., Horn, A. B., Holtzman, N. S., Edwards, T. S., Pennebaker, J. W., & Mehl, M. R. (2019). Depression, Negative Emotionality, and Self-Referential Language: A Multi-Lab, Multi-Measure, and Multi-Language-Task Research Synthesis. Journal of Personality and Social Psychology, 116(5), 817–834. https://doi.org/10.1037/pspp0000187.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I ', \"I'm \", \"I've \", \"I'll \", \"I'd \", ' me ', 'Me ', ' myself ', 'Myself ']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounAll = [\"I \", \n",
    "               \"I'm \", \n",
    "               \"I've \", \n",
    "               \"I'll \", \n",
    "               \"I'd \", \n",
    "               \" me \", \n",
    "               \"Me \", \n",
    "               \" myself \", \n",
    "               \"Myself \"]\n",
    "pronounAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I ', \"I'm \", \"I've \", \"I'll \", \"I'd \"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounSub = [\"I \", \"I'm \", \"I've \", \"I'll \", \"I'd \"]\n",
    "pronounSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' me ', 'Me ', ' myself ', 'Myself ']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounObj = [\" me \", \n",
    "               \"Me \", \n",
    "               \" myself \", \n",
    "               \"Myself \"]\n",
    "pronounObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts = [x.lower() for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"December 3 1898. My Dear Aunt Maggie I have intended writing to you for some time but I suppose you have almost given up expecting to hear from me. Bella taught me how to make Rennaissance Renaissance and I am sending you a little center-piece I made. It is the first piece I did and perhaps not quite so well done as the next will be. Len insists that he must send you something and put in one of his own cards. We are sending it inside a newspaper and hope it will reach you all right by Christmas. I was very glad to receive your letter some time ago We are all well but Mamma says to tell you something that she knows you will be sorry to hear. My cousin Uncle Joe's second son Joseph Jr. Junior died on the fourth of December out in Denver Colorado where he had gone for his health three months before. It was a great shock to us all as it was the first break in a family of nine children and the first death since his Mother's eighteen years ago. He was just twenty-six years old and had been married four years. His wife brought home the body and he was buried last Sunday. I hope you are feeling better and are quite strong again. I always live in the hope that I may some day get over to see you or that you may come and see us. Give my love to Aunt Jeannie and Jack and we all join in sending a good share to yourself. Your loving niece Marion Denham Wilson.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Subjective\n",
    "\n",
    "Count = 0\n",
    "\n",
    "for i in pronounSub:\n",
    "    Count = texts[chunk].count(i) + Count\n",
    "\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Objective\n",
    "\n",
    "Count = 0\n",
    "\n",
    "for i in pronounObj:\n",
    "    Count = texts[chunk].count(i) + Count\n",
    "\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# All pronouns\n",
    "\n",
    "Count = 0\n",
    "\n",
    "for i in pronounAll:\n",
    "    Count = texts[chunk].count(i) + Count\n",
    "\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run on all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392\n",
      "[13, 10, 3, 13, 7, 4, 16, 14, 5]\n"
     ]
    }
   ],
   "source": [
    "# Now the rest\n",
    "\n",
    "fppAll_Ct = []\n",
    "\n",
    "for item in texts:\n",
    "    Count = 0\n",
    "    for i in pronounAll:\n",
    "        #print(texts[0].count(i))\n",
    "        Count = item.count(i) + Count\n",
    "    \n",
    "    fppAll_Ct.append(Count)\n",
    "\n",
    "print(len(fppAll_Ct))\n",
    "print(fppAll_Ct[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392\n",
      "[12, 9, 2, 9, 7, 4, 16, 13, 5]\n"
     ]
    }
   ],
   "source": [
    "# Now just subjective pronouns\n",
    "\n",
    "fppSub_Ct = []\n",
    "\n",
    "for item in texts:\n",
    "    Count = 0\n",
    "    for i in pronounSub:\n",
    "        #print(texts[0].count(i))\n",
    "        Count = item.count(i) + Count\n",
    "    \n",
    "    fppSub_Ct.append(Count)\n",
    "\n",
    "print(len(fppSub_Ct))\n",
    "print(fppSub_Ct[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392\n",
      "[1, 1, 1, 4, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Now just subjective pronouns\n",
    "\n",
    "fppObj_Ct = []\n",
    "\n",
    "for item in texts:\n",
    "    Count = 0\n",
    "    for i in pronounObj:\n",
    "        #print(texts[0].count(i))\n",
    "        Count = item.count(i) + Count\n",
    "    \n",
    "    fppObj_Ct.append(Count)\n",
    "\n",
    "print(len(fppObj_Ct))\n",
    "print(fppObj_Ct[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new variables to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2392 entries, 0 to 2391\n",
      "Data columns (total 37 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   docID-AT          2392 non-null   int64  \n",
      " 1   docid             2392 non-null   object \n",
      " 2   docyear           2392 non-null   int64  \n",
      " 3   docmonth          2364 non-null   float64\n",
      " 4   authorName        2177 non-null   object \n",
      " 5   docauthorid       2392 non-null   object \n",
      " 6   authorLocation    2392 non-null   object \n",
      " 7   authorGender      2392 non-null   object \n",
      " 8   nationalOrigin    2392 non-null   object \n",
      " 9   irish             2392 non-null   bool   \n",
      " 10  otherUK           2392 non-null   bool   \n",
      " 11  relMin            1065 non-null   object \n",
      " 12  catholic          1065 non-null   object \n",
      " 13  otherChristian    1065 non-null   object \n",
      " 14  U                 1253 non-null   object \n",
      " 15  M                 1276 non-null   object \n",
      " 16  S                 1245 non-null   object \n",
      " 17  F                 1243 non-null   object \n",
      " 18  L                 1266 non-null   object \n",
      " 19  text              2392 non-null   object \n",
      " 20  sequence          2392 non-null   int64  \n",
      " 21  totalTokens       2392 non-null   int64  \n",
      " 22  uniqueTokens      2392 non-null   int64  \n",
      " 23  lexicalDiversity  2392 non-null   float64\n",
      " 24  scoreNeg          2392 non-null   float64\n",
      " 25  scoreNeu          2392 non-null   float64\n",
      " 26  scorePos          2392 non-null   float64\n",
      " 27  scoreCom          2392 non-null   float64\n",
      " 28  chunks            2392 non-null   int64  \n",
      " 29  position          2392 non-null   float64\n",
      " 30  topicNumber       2392 non-null   int64  \n",
      " 31  mentsDis          2392 non-null   object \n",
      " 32  mentsTot          2392 non-null   int64  \n",
      " 33  indsTot           2392 non-null   int64  \n",
      " 34  fppAll_Ct         2392 non-null   int64  \n",
      " 35  fppSub_Ct         2392 non-null   int64  \n",
      " 36  fppObj_Ct         2392 non-null   int64  \n",
      "dtypes: bool(2), float64(7), int64(12), object(16)\n",
      "memory usage: 677.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df['mentsDis'] = [', '.join(x) for x in mentsDis]\n",
    "df['mentsTot'] = mentsTot\n",
    "df['indsTot'] = indsTot\n",
    "df['fppAll_Ct'] = fppAll_Ct\n",
    "df['fppSub_Ct'] = fppSub_Ct\n",
    "df['fppObj_Ct'] = fppObj_Ct\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID-AT</th>\n",
       "      <th>docid</th>\n",
       "      <th>docyear</th>\n",
       "      <th>docmonth</th>\n",
       "      <th>authorName</th>\n",
       "      <th>docauthorid</th>\n",
       "      <th>authorLocation</th>\n",
       "      <th>authorGender</th>\n",
       "      <th>nationalOrigin</th>\n",
       "      <th>irish</th>\n",
       "      <th>...</th>\n",
       "      <th>scoreCom</th>\n",
       "      <th>chunks</th>\n",
       "      <th>position</th>\n",
       "      <th>topicNumber</th>\n",
       "      <th>mentsDis</th>\n",
       "      <th>mentsTot</th>\n",
       "      <th>indsTot</th>\n",
       "      <th>fppAll_Ct</th>\n",
       "      <th>fppSub_Ct</th>\n",
       "      <th>fppObj_Ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20910</td>\n",
       "      <td>1891</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Isabella Weir Moore</td>\n",
       "      <td>IED0107</td>\n",
       "      <td>USA</td>\n",
       "      <td>F</td>\n",
       "      <td>Irish</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Isabella Moore, Willie, Bye Isabella Weir</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21062</td>\n",
       "      <td>1871</td>\n",
       "      <td>11.0</td>\n",
       "      <td>E. Rothwell</td>\n",
       "      <td>IED0179</td>\n",
       "      <td>Canada</td>\n",
       "      <td>F</td>\n",
       "      <td>Irish</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279733</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>Kate, Lydia, Maria, Bissin, Garnetts, Tom Fitz...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>21062</td>\n",
       "      <td>1871</td>\n",
       "      <td>11.0</td>\n",
       "      <td>E. Rothwell</td>\n",
       "      <td>IED0179</td>\n",
       "      <td>Canada</td>\n",
       "      <td>F</td>\n",
       "      <td>Irish</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081575</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Edith, Edward, Annie, Richard Garnett, Kate, E...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21324</td>\n",
       "      <td>1892</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Isabella Weir Moore</td>\n",
       "      <td>IED0107</td>\n",
       "      <td>USA</td>\n",
       "      <td>F</td>\n",
       "      <td>Irish</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942300</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Anna, Brotherinlaw, Husband</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>21334</td>\n",
       "      <td>1891</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Mary Savage</td>\n",
       "      <td>IED0621</td>\n",
       "      <td>USA</td>\n",
       "      <td>F</td>\n",
       "      <td>Irish</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146967</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>Lizzie, Johns, James Wm, William N, Nick John,...</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   docID-AT  docid  docyear  docmonth           authorName docauthorid  \\\n",
       "0         1  20910     1891       7.0  Isabella Weir Moore     IED0107   \n",
       "1         2  21062     1871      11.0          E. Rothwell     IED0179   \n",
       "2         3  21062     1871      11.0          E. Rothwell     IED0179   \n",
       "3         4  21324     1892       5.0  Isabella Weir Moore     IED0107   \n",
       "4         5  21334     1891      10.0          Mary Savage     IED0621   \n",
       "\n",
       "  authorLocation authorGender nationalOrigin  irish  ...  scoreCom chunks  \\\n",
       "0            USA            F          Irish   True  ...  0.515100      1   \n",
       "1         Canada            F          Irish   True  ...  0.279733      2   \n",
       "2         Canada            F          Irish   True  ...  0.081575      2   \n",
       "3            USA            F          Irish   True  ...  0.942300      1   \n",
       "4            USA            F          Irish   True  ...  0.146967      2   \n",
       "\n",
       "  position topicNumber                                           mentsDis  \\\n",
       "0      1.0           3          Isabella Moore, Willie, Bye Isabella Weir   \n",
       "1      0.5           3  Kate, Lydia, Maria, Bissin, Garnetts, Tom Fitz...   \n",
       "2      1.0           4  Edith, Edward, Annie, Richard Garnett, Kate, E...   \n",
       "3      1.0           3                        Anna, Brotherinlaw, Husband   \n",
       "4      0.5           4  Lizzie, Johns, James Wm, William N, Nick John,...   \n",
       "\n",
       "  mentsTot indsTot fppAll_Ct fppSub_Ct fppObj_Ct  \n",
       "0        3       3        13        12         1  \n",
       "1       11      10        10         9         1  \n",
       "2        6       6         3         2         1  \n",
       "3        4       3        13         9         4  \n",
       "4       13      12         7         7         0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"20240611_PhD_FinalData-LtrChk.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
