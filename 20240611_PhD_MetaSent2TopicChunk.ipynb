{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge topic labels to chunk dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim\n",
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmanized text\n",
    "with open(\"20240608_PhD_LtrChkLem-N.txt\", \"rb\") as fp:   # Unpickling\n",
    "    data_lemmatized = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = models.ldamodel.LdaModel.load('20240610_PhD_TopicLtrMAL11a9i4k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed because I converted from Mallet to LDA in 20240331_PhD_TopicLetterChkNV-Mallet\n",
    "# Load saved mallet\n",
    "# lda_mallet = gensim.models.wrappers.LdaMallet.load(\"20240221_PhD_TopicChkMAL14\")\n",
    "# Convert to LDA\n",
    "# ldamodel = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(lda_mallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.086*\"day\" + 0.054*\"time\" + 0.045*\"winter\" + 0.038*\"summer\" + '\n",
      "  '0.037*\"weather\" + 0.030*\"health\" + 0.026*\"week\" + 0.023*\"month\" + '\n",
      "  '0.020*\"place\" + 0.018*\"country\" + 0.018*\"town\" + 0.017*\"spring\" + '\n",
      "  '0.017*\"snow\" + 0.012*\"year\" + 0.011*\"rain\" + 0.011*\"fall\" + 0.011*\"frost\" + '\n",
      "  '0.011*\"heat\" + 0.009*\"account\" + 0.009*\"climate\"'),\n",
      " (1,\n",
      "  '0.055*\"dollar\" + 0.053*\"work\" + 0.044*\"money\" + 0.031*\"year\" + 0.027*\"day\" '\n",
      "  '+ 0.022*\"time\" + 0.021*\"business\" + 0.020*\"pound\" + 0.020*\"week\" + '\n",
      "  '0.018*\"month\" + 0.017*\"country\" + 0.017*\"cent\" + 0.015*\"house\" + '\n",
      "  '0.015*\"board\" + 0.014*\"man\" + 0.013*\"place\" + 0.012*\"wage\" + 0.012*\"pay\" + '\n",
      "  '0.011*\"property\" + 0.011*\"summer\"'),\n",
      " (2,\n",
      "  '0.046*\"land\" + 0.036*\"pound\" + 0.034*\"acre\" + 0.032*\"farm\" + '\n",
      "  '0.026*\"country\" + 0.024*\"year\" + 0.016*\"price\" + 0.016*\"crop\" + '\n",
      "  '0.016*\"wheat\" + 0.012*\"bushel\" + 0.012*\"potato\" + 0.012*\"farmer\" + '\n",
      "  '0.011*\"market\" + 0.011*\"wood\" + 0.010*\"money\" + 0.010*\"lot\" + 0.010*\"horse\" '\n",
      "  '+ 0.009*\"cow\" + 0.009*\"spring\" + 0.009*\"foot\"'),\n",
      " (3,\n",
      "  '0.140*\"letter\" + 0.086*\"time\" + 0.027*\"home\" + 0.024*\"news\" + '\n",
      "  '0.022*\"friend\" + 0.022*\"month\" + 0.020*\"write\" + 0.019*\"sister\" + '\n",
      "  '0.018*\"place\" + 0.016*\"opportunity\" + 0.015*\"day\" + 0.013*\"pleasure\" + '\n",
      "  '0.013*\"return\" + 0.012*\"care\" + 0.012*\"week\" + 0.012*\"thing\" + '\n",
      "  '0.011*\"writing\" + 0.011*\"picture\" + 0.011*\"mail\" + 0.010*\"answer\"'),\n",
      " (4,\n",
      "  '0.062*\"brother\" + 0.056*\"family\" + 0.044*\"friend\" + 0.039*\"mother\" + '\n",
      "  '0.038*\"letter\" + 0.030*\"sister\" + 0.027*\"health\" + 0.026*\"child\" + '\n",
      "  '0.026*\"daughter\" + 0.025*\"year\" + 0.025*\"son\" + 0.021*\"aunt\" + '\n",
      "  '0.021*\"uncle\" + 0.021*\"wife\" + 0.018*\"time\" + 0.017*\"cousin\" + '\n",
      "  '0.016*\"father\" + 0.014*\"death\" + 0.013*\"home\" + 0.013*\"girl\"'),\n",
      " (5,\n",
      "  '0.029*\"room\" + 0.027*\"house\" + 0.020*\"water\" + 0.019*\"tree\" + 0.019*\"side\" '\n",
      "  '+ 0.018*\"day\" + 0.017*\"morning\" + 0.015*\"river\" + 0.015*\"flower\" + '\n",
      "  '0.015*\"fire\" + 0.014*\"wood\" + 0.013*\"place\" + 0.011*\"garden\" + '\n",
      "  '0.010*\"window\" + 0.010*\"door\" + 0.010*\"town\" + 0.010*\"night\" + 0.009*\"mile\" '\n",
      "  '+ 0.009*\"road\" + 0.009*\"building\"'),\n",
      " (6,\n",
      "  '0.039*\"book\" + 0.028*\"work\" + 0.025*\"hand\" + 0.022*\"paper\" + 0.021*\"life\" + '\n",
      "  '0.015*\"copy\" + 0.011*\"thing\" + 0.011*\"mind\" + 0.010*\"letter\" + '\n",
      "  '0.009*\"interest\" + 0.009*\"pen\" + 0.009*\"order\" + 0.009*\"story\" + '\n",
      "  '0.008*\"truth\" + 0.008*\"spirit\" + 0.007*\"eye\" + 0.007*\"success\" + '\n",
      "  '0.007*\"history\" + 0.006*\"world\" + 0.006*\"fear\"'),\n",
      " (7,\n",
      "  '0.046*\"week\" + 0.041*\"child\" + 0.030*\"day\" + 0.027*\"school\" + 0.024*\"boy\" + '\n",
      "  '0.023*\"home\" + 0.023*\"night\" + 0.020*\"evening\" + 0.017*\"baby\" + '\n",
      "  '0.016*\"today\" + 0.016*\"yesterday\" + 0.015*\"church\" + 0.015*\"morning\" + '\n",
      "  '0.015*\"time\" + 0.015*\"bed\" + 0.014*\"girl\" + 0.011*\"visit\" + 0.010*\"tea\" + '\n",
      "  '0.010*\"island\" + 0.010*\"tomorrow\"'),\n",
      " (8,\n",
      "  '0.018*\"ship\" + 0.018*\"boat\" + 0.016*\"day\" + 0.013*\"vessel\" + 0.012*\"gold\" + '\n",
      "  '0.012*\"sea\" + 0.012*\"thing\" + 0.012*\"board\" + 0.010*\"passage\" + '\n",
      "  '0.010*\"night\" + 0.010*\"kind\" + 0.009*\"fellow\" + 0.009*\"luggage\" + '\n",
      "  '0.009*\"provision\" + 0.009*\"passenger\" + 0.008*\"voyage\" + 0.008*\"steamer\" + '\n",
      "  '0.008*\"sail\" + 0.008*\"arrival\" + 0.008*\"water\"'),\n",
      " (9,\n",
      "  '0.027*\"heart\" + 0.026*\"life\" + 0.024*\"child\" + 0.022*\"friend\" + '\n",
      "  '0.018*\"mother\" + 0.018*\"death\" + 0.017*\"husband\" + 0.015*\"world\" + '\n",
      "  '0.013*\"year\" + 0.013*\"kind\" + 0.012*\"wife\" + 0.012*\"trial\" + 0.011*\"age\" + '\n",
      "  '0.011*\"woman\" + 0.010*\"loss\" + 0.010*\"girl\" + 0.010*\"mind\" + '\n",
      "  '0.010*\"trouble\" + 0.009*\"sorrow\" + 0.009*\"hand\"'),\n",
      " (10,\n",
      "  '0.058*\"country\" + 0.049*\"people\" + 0.022*\"year\" + 0.022*\"man\" + '\n",
      "  '0.018*\"land\" + 0.013*\"government\" + 0.012*\"place\" + 0.009*\"manner\" + '\n",
      "  '0.009*\"war\" + 0.009*\"city\" + 0.008*\"matter\" + 0.008*\"interest\" + '\n",
      "  '0.008*\"difficulty\" + 0.008*\"number\" + 0.007*\"state\" + 0.007*\"law\" + '\n",
      "  '0.007*\"office\" + 0.007*\"company\" + 0.007*\"side\" + 0.006*\"food\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(sorted(ldamodel.print_topics(num_words=20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2392 entries, 0 to 2391\n",
      "Data columns (total 30 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   docID-AT          2392 non-null   int64  \n",
      " 1   docid             2392 non-null   object \n",
      " 2   docyear           2392 non-null   int64  \n",
      " 3   docmonth          2364 non-null   float64\n",
      " 4   authorName        2177 non-null   object \n",
      " 5   docauthorid       2392 non-null   object \n",
      " 6   authorLocation    2392 non-null   object \n",
      " 7   authorGender      2392 non-null   object \n",
      " 8   nationalOrigin    2392 non-null   object \n",
      " 9   irish             2392 non-null   bool   \n",
      " 10  otherUK           2392 non-null   bool   \n",
      " 11  relMin            1065 non-null   object \n",
      " 12  catholic          1065 non-null   object \n",
      " 13  otherChristian    1065 non-null   object \n",
      " 14  U                 1253 non-null   object \n",
      " 15  M                 1276 non-null   object \n",
      " 16  S                 1245 non-null   object \n",
      " 17  F                 1243 non-null   object \n",
      " 18  L                 1266 non-null   object \n",
      " 19  text              2392 non-null   object \n",
      " 20  sequence          2392 non-null   int64  \n",
      " 21  totalTokens       2392 non-null   int64  \n",
      " 22  uniqueTokens      2392 non-null   int64  \n",
      " 23  lexicalDiversity  2392 non-null   float64\n",
      " 24  scoreNeg          2392 non-null   float64\n",
      " 25  scoreNeu          2392 non-null   float64\n",
      " 26  scorePos          2392 non-null   float64\n",
      " 27  scoreCom          2392 non-null   float64\n",
      " 28  chunks            2392 non-null   int64  \n",
      " 29  position          2392 non-null   float64\n",
      "dtypes: bool(2), float64(7), int64(6), object(15)\n",
      "memory usage: 528.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Metadata\n",
    "df = pd.read_csv(\"20240608_PhD_Data4TopicModel-LetterChunk.csv\") \n",
    "df = df.rename(columns={'Unnamed: 0':'docID-AT'})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.text.values.tolist()\n",
    "# data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Functions & Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics(ldamodel=ldamodel, corpus=corpus, texts=texts):\n",
    "    # Init output\n",
    "    topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num, topn=20)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                topics_df = topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    topics_df = pd.concat([topics_df, contents], axis=1)\n",
    "    return(topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>letter, time, home, news, friend, month, write...</td>\n",
       "      <td>July 18 1891 Dear Sister I have waited until I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>letter, time, home, news, friend, month, write...</td>\n",
       "      <td>Nov 17th My dearest Kate I got this interestin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2601</td>\n",
       "      <td>brother, family, friend, mother, letter, siste...</td>\n",
       "      <td>better account since he went. The poor parents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2388</td>\n",
       "      <td>letter, time, home, news, friend, month, write...</td>\n",
       "      <td>May 25 1892 Dear Sister I write once to Bid yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3123</td>\n",
       "      <td>brother, family, friend, mother, letter, siste...</td>\n",
       "      <td>1891 Oct. 12th Miss Weir Dear friend I now ans...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0               3              0.2828   \n",
       "1            1               3              0.2060   \n",
       "2            2               4              0.2601   \n",
       "3            3               3              0.2388   \n",
       "4            4               4              0.3123   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  letter, time, home, news, friend, month, write...   \n",
       "1  letter, time, home, news, friend, month, write...   \n",
       "2  brother, family, friend, mother, letter, siste...   \n",
       "3  letter, time, home, news, friend, month, write...   \n",
       "4  brother, family, friend, mother, letter, siste...   \n",
       "\n",
       "                                                Text  \n",
       "0  July 18 1891 Dear Sister I have waited until I...  \n",
       "1  Nov 17th My dearest Kate I got this interestin...  \n",
       "2  better account since he went. The poor parents...  \n",
       "3  May 25 1892 Dear Sister I write once to Bid yo...  \n",
       "4  1891 Oct. 12th Miss Weir Dear friend I now ans...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the topic for the first 10 rows. \n",
    "df_topic_keywords = format_topics(ldamodel=ldamodel, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_Text_topicNumber = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(data):\n",
    "    topic_dist = ldamodel.get_document_topics(corpus[index])\n",
    "\n",
    "    # topic_dist is a list of tuples: each tuple has a topic number with its corresponding proportion\n",
    "    sorted_topic_dist = sorted(topic_dist, key=lambda x: (x[1]), reverse=True) # Sort it in descending order\n",
    "    \n",
    "    # Pick the top one:\n",
    "    topic_number = sorted_topic_dist[0][0]\n",
    "    map_Text_topicNumber[item] = topic_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first key value pair in dictionary (text, label)\n",
    "# dict(list(map_Text_topicNumber.items())[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>docauthorid</th>\n",
       "      <th>text</th>\n",
       "      <th>topicNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20910</td>\n",
       "      <td>IED0107</td>\n",
       "      <td>July 18 1891 Dear Sister I have waited until I...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21062</td>\n",
       "      <td>IED0179</td>\n",
       "      <td>Nov 17th My dearest Kate I got this interestin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21062</td>\n",
       "      <td>IED0179</td>\n",
       "      <td>better account since he went. The poor parents...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21324</td>\n",
       "      <td>IED0107</td>\n",
       "      <td>May 25 1892 Dear Sister I write once to Bid yo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21334</td>\n",
       "      <td>IED0621</td>\n",
       "      <td>1891 Oct. 12th Miss Weir Dear friend I now ans...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21334</td>\n",
       "      <td>IED0621</td>\n",
       "      <td>is that big strong girl Miss Harrison got on h...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21354</td>\n",
       "      <td>IED0958</td>\n",
       "      <td>February 1st 90 Dear Cousin It is with pleasur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21354</td>\n",
       "      <td>IED0958</td>\n",
       "      <td>now so I think So I think I will soon be able ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21470</td>\n",
       "      <td>IED0099</td>\n",
       "      <td>March 6th 1800 My dear Maggie I was sorry to l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21470</td>\n",
       "      <td>IED0099</td>\n",
       "      <td>not go in. it was after 5 Pm and the doors are...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21470</td>\n",
       "      <td>IED0099</td>\n",
       "      <td>with the nuts on them the Palm clematis and hi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    docid docauthorid                                               text  \\\n",
       "0   20910     IED0107  July 18 1891 Dear Sister I have waited until I...   \n",
       "1   21062     IED0179  Nov 17th My dearest Kate I got this interestin...   \n",
       "2   21062     IED0179  better account since he went. The poor parents...   \n",
       "3   21324     IED0107  May 25 1892 Dear Sister I write once to Bid yo...   \n",
       "4   21334     IED0621  1891 Oct. 12th Miss Weir Dear friend I now ans...   \n",
       "5   21334     IED0621  is that big strong girl Miss Harrison got on h...   \n",
       "6   21354     IED0958  February 1st 90 Dear Cousin It is with pleasur...   \n",
       "7   21354     IED0958  now so I think So I think I will soon be able ...   \n",
       "8   21470     IED0099  March 6th 1800 My dear Maggie I was sorry to l...   \n",
       "9   21470     IED0099  not go in. it was after 5 Pm and the doors are...   \n",
       "10  21470     IED0099  with the nuts on them the Palm clematis and hi...   \n",
       "\n",
       "    topicNumber  \n",
       "0             3  \n",
       "1             3  \n",
       "2             4  \n",
       "3             3  \n",
       "4             4  \n",
       "5             4  \n",
       "6             0  \n",
       "7             2  \n",
       "8             5  \n",
       "9             5  \n",
       "10            5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topicNumber'] = df['text'].map(map_Text_topicNumber)\n",
    "df.loc[:10,['docid', 'docauthorid', 'text', 'topicNumber']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7281</td>\n",
       "      <td>day, time, winter, summer, weather, health, we...</td>\n",
       "      <td>durning the night. this day fine and clear. 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>dollar, work, money, year, day, time, business...</td>\n",
       "      <td>At Chippawa I received employment for seventee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>land, pound, acre, farm, country, year, price,...</td>\n",
       "      <td>increase is about 20 sowing only one bushel Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6189</td>\n",
       "      <td>letter, time, home, news, friend, month, write...</td>\n",
       "      <td>to hear Mary Cumming stayed so long with you. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.7057</td>\n",
       "      <td>brother, family, friend, mother, letter, siste...</td>\n",
       "      <td>he left a wife and 2 children and one born sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.7566</td>\n",
       "      <td>room, house, water, tree, side, day, morning, ...</td>\n",
       "      <td>and should you look around to examine the tree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>book, work, hand, paper, life, copy, thing, mi...</td>\n",
       "      <td>as a writer. His fame like many of the great e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>week, child, day, school, boy, home, night, ev...</td>\n",
       "      <td>Sarah to Martha January 4 This being the anniv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.7638</td>\n",
       "      <td>ship, boat, day, vessel, gold, sea, thing, boa...</td>\n",
       "      <td>were fellow sufferers. All the passengers part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.7638</td>\n",
       "      <td>heart, life, child, friend, mother, death, hus...</td>\n",
       "      <td>greeting. Her letter informed me of your sad b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.7312</td>\n",
       "      <td>country, people, year, man, land, government, ...</td>\n",
       "      <td>of government from being brought into conflict...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic_Num  Topic_Perc_Contrib  \\\n",
       "0           0              0.7281   \n",
       "1           1              0.7375   \n",
       "2           2              0.7958   \n",
       "3           3              0.6189   \n",
       "4           4              0.7057   \n",
       "5           5              0.7566   \n",
       "6           6              0.7586   \n",
       "7           7              0.6810   \n",
       "8           8              0.7638   \n",
       "9           9              0.7638   \n",
       "10         10              0.7312   \n",
       "\n",
       "                                             Keywords  \\\n",
       "0   day, time, winter, summer, weather, health, we...   \n",
       "1   dollar, work, money, year, day, time, business...   \n",
       "2   land, pound, acre, farm, country, year, price,...   \n",
       "3   letter, time, home, news, friend, month, write...   \n",
       "4   brother, family, friend, mother, letter, siste...   \n",
       "5   room, house, water, tree, side, day, morning, ...   \n",
       "6   book, work, hand, paper, life, copy, thing, mi...   \n",
       "7   week, child, day, school, boy, home, night, ev...   \n",
       "8   ship, boat, day, vessel, gold, sea, thing, boa...   \n",
       "9   heart, life, child, friend, mother, death, hus...   \n",
       "10  country, people, year, man, land, government, ...   \n",
       "\n",
       "                                                 Text  \n",
       "0   durning the night. this day fine and clear. 12...  \n",
       "1   At Chippawa I received employment for seventee...  \n",
       "2   increase is about 20 sowing only one bushel Wi...  \n",
       "3   to hear Mary Cumming stayed so long with you. ...  \n",
       "4   he left a wife and 2 children and one born sin...  \n",
       "5   and should you look around to examine the tree...  \n",
       "6   as a writer. His fame like many of the great e...  \n",
       "7   Sarah to Martha January 4 This being the anniv...  \n",
       "8   were fellow sufferers. All the passengers part...  \n",
       "9   greeting. Her letter informed me of your sad b...  \n",
       "10  of government from being brought into conflict...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "topics_outdf_grpd = df_topic_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in topics_outdf_grpd:\n",
    "    topics_sorteddf_mallet = pd.concat([topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "topics_sorteddf_mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     299\n",
       "7     292\n",
       "4     266\n",
       "9     263\n",
       "2     227\n",
       "10    214\n",
       "5     182\n",
       "0     173\n",
       "6     171\n",
       "1     158\n",
       "8     147\n",
       "Name: Dominant_Topic, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_keywords['Dominant_Topic'].value_counts()\n",
    "topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     0.1250\n",
       "7     0.1221\n",
       "4     0.1112\n",
       "9     0.1099\n",
       "2     0.0949\n",
       "10    0.0895\n",
       "5     0.0761\n",
       "0     0.0723\n",
       "6     0.0715\n",
       "1     0.0661\n",
       "8     0.0615\n",
       "Name: Dominant_Topic, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "topic_contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>day, time, winter, summer, weather, health, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>dollar, work, money, year, day, time, business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>land, pound, acre, farm, country, year, price,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>letter, time, home, news, friend, month, write...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>brother, family, friend, mother, letter, siste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>room, house, water, tree, side, day, morning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>book, work, hand, paper, life, copy, thing, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>7</td>\n",
       "      <td>week, child, day, school, boy, home, night, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>ship, boat, day, vessel, gold, sea, thing, boa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>heart, life, child, friend, mother, death, hus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>10</td>\n",
       "      <td>country, people, year, man, land, government, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant_Topic                                     Topic_Keywords\n",
       "6                0  day, time, winter, summer, weather, health, we...\n",
       "70               1  dollar, work, money, year, day, time, business...\n",
       "7                2  land, pound, acre, farm, country, year, price,...\n",
       "0                3  letter, time, home, news, friend, month, write...\n",
       "2                4  brother, family, friend, mother, letter, siste...\n",
       "8                5  room, house, water, tree, side, day, morning, ...\n",
       "11               6  book, work, hand, paper, life, copy, thing, mi...\n",
       "57               7  week, child, day, school, boy, home, night, ev...\n",
       "19               8  ship, boat, day, vessel, gold, sea, thing, boa...\n",
       "25               9  heart, life, child, friend, mother, death, hus...\n",
       "67              10  country, people, year, man, land, government, ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_keywords[['Dominant_Topic', 'Topic_Keywords']].drop_duplicates().sort_values(by = 'Dominant_Topic')\n",
    "topic_num_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>day, time, winter, summer, weather, health, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dollar, work, money, year, day, time, business...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>land, pound, acre, farm, country, year, price,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>letter, time, home, news, friend, month, write...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>brother, family, friend, mother, letter, siste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>room, house, water, tree, side, day, morning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>book, work, hand, paper, life, copy, thing, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>week, child, day, school, boy, home, night, ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>ship, boat, day, vessel, gold, sea, thing, boa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>heart, life, child, friend, mother, death, hus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>country, people, year, man, land, government, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant_Topic                                     Topic_Keywords\n",
       "0                0  day, time, winter, summer, weather, health, we...\n",
       "1                1  dollar, work, money, year, day, time, business...\n",
       "2                2  land, pound, acre, farm, country, year, price,...\n",
       "3                3  letter, time, home, news, friend, month, write...\n",
       "4                4  brother, family, friend, mother, letter, siste...\n",
       "5                5  room, house, water, tree, side, day, morning, ...\n",
       "6                6  book, work, hand, paper, life, copy, thing, mi...\n",
       "7                7  week, child, day, school, boy, home, night, ev...\n",
       "8                8  ship, boat, day, vessel, gold, sea, thing, boa...\n",
       "9                9  heart, life, child, friend, mother, death, hus...\n",
       "10              10  country, people, year, man, land, government, ..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_num_keywords.reset_index(drop=True, inplace=True)\n",
    "topic_num_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering\n",
    "# topic_num_keywords = topic_num_keywords.reindex([11,17,14,5,3,2,4,0,18,20,7,1,15,10,16,19,9,6,8,12,13])\n",
    "# topic_num_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>counts</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>day, time, winter, summer, weather, health, we...</td>\n",
       "      <td>173</td>\n",
       "      <td>0.0723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dollar, work, money, year, day, time, business...</td>\n",
       "      <td>158</td>\n",
       "      <td>0.0661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>land, pound, acre, farm, country, year, price,...</td>\n",
       "      <td>227</td>\n",
       "      <td>0.0949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>letter, time, home, news, friend, month, write...</td>\n",
       "      <td>299</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>brother, family, friend, mother, letter, siste...</td>\n",
       "      <td>266</td>\n",
       "      <td>0.1112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>room, house, water, tree, side, day, morning, ...</td>\n",
       "      <td>182</td>\n",
       "      <td>0.0761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>book, work, hand, paper, life, copy, thing, mi...</td>\n",
       "      <td>171</td>\n",
       "      <td>0.0715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>week, child, day, school, boy, home, night, ev...</td>\n",
       "      <td>292</td>\n",
       "      <td>0.1221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>ship, boat, day, vessel, gold, sea, thing, boa...</td>\n",
       "      <td>147</td>\n",
       "      <td>0.0615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>heart, life, child, friend, mother, death, hus...</td>\n",
       "      <td>263</td>\n",
       "      <td>0.1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>country, people, year, man, land, government, ...</td>\n",
       "      <td>214</td>\n",
       "      <td>0.0895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dominant_Topic                                     Topic_Keywords  counts  \\\n",
       "0                0  day, time, winter, summer, weather, health, we...     173   \n",
       "1                1  dollar, work, money, year, day, time, business...     158   \n",
       "2                2  land, pound, acre, farm, country, year, price,...     227   \n",
       "3                3  letter, time, home, news, friend, month, write...     299   \n",
       "4                4  brother, family, friend, mother, letter, siste...     266   \n",
       "5                5  room, house, water, tree, side, day, morning, ...     182   \n",
       "6                6  book, work, hand, paper, life, copy, thing, mi...     171   \n",
       "7                7  week, child, day, school, boy, home, night, ev...     292   \n",
       "8                8  ship, boat, day, vessel, gold, sea, thing, boa...     147   \n",
       "9                9  heart, life, child, friend, mother, death, hus...     263   \n",
       "10              10  country, people, year, man, land, government, ...     214   \n",
       "\n",
       "    contribution  \n",
       "0         0.0723  \n",
       "1         0.0661  \n",
       "2         0.0949  \n",
       "3         0.1250  \n",
       "4         0.1112  \n",
       "5         0.0761  \n",
       "6         0.0715  \n",
       "7         0.1221  \n",
       "8         0.0615  \n",
       "9         0.1099  \n",
       "10        0.0895  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts.rename('counts'), topic_contribution.rename('contribution')], axis=1).sort_values(by = 'Dominant_Topic')\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topics.to_csv(\"20240611_PhD_TopicsLtrChkMAL11a9i4k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2392 entries, 0 to 2391\n",
      "Data columns (total 31 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   docID-AT          2392 non-null   int64  \n",
      " 1   docid             2392 non-null   object \n",
      " 2   docyear           2392 non-null   int64  \n",
      " 3   docmonth          2364 non-null   float64\n",
      " 4   authorName        2177 non-null   object \n",
      " 5   docauthorid       2392 non-null   object \n",
      " 6   authorLocation    2392 non-null   object \n",
      " 7   authorGender      2392 non-null   object \n",
      " 8   nationalOrigin    2392 non-null   object \n",
      " 9   irish             2392 non-null   bool   \n",
      " 10  otherUK           2392 non-null   bool   \n",
      " 11  relMin            1065 non-null   object \n",
      " 12  catholic          1065 non-null   object \n",
      " 13  otherChristian    1065 non-null   object \n",
      " 14  U                 1253 non-null   object \n",
      " 15  M                 1276 non-null   object \n",
      " 16  S                 1245 non-null   object \n",
      " 17  F                 1243 non-null   object \n",
      " 18  L                 1266 non-null   object \n",
      " 19  text              2392 non-null   object \n",
      " 20  sequence          2392 non-null   int64  \n",
      " 21  totalTokens       2392 non-null   int64  \n",
      " 22  uniqueTokens      2392 non-null   int64  \n",
      " 23  lexicalDiversity  2392 non-null   float64\n",
      " 24  scoreNeg          2392 non-null   float64\n",
      " 25  scoreNeu          2392 non-null   float64\n",
      " 26  scorePos          2392 non-null   float64\n",
      " 27  scoreCom          2392 non-null   float64\n",
      " 28  chunks            2392 non-null   int64  \n",
      " 29  position          2392 non-null   float64\n",
      " 30  topicNumber       2392 non-null   int64  \n",
      "dtypes: bool(2), float64(7), int64(7), object(15)\n",
      "memory usage: 546.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"20240611_PhD_Data4NER-LtrChk.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
