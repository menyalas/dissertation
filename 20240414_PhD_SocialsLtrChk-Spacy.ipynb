{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Letter Chunk Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2270 entries, 0 to 2269\n",
      "Data columns (total 29 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   docID-AT          2270 non-null   int64  \n",
      " 1   docauthorid       2270 non-null   object \n",
      " 2   docauthorname     2270 non-null   object \n",
      " 3   docid             2270 non-null   object \n",
      " 4   docyear           2235 non-null   float64\n",
      " 5   docmonth          2171 non-null   float64\n",
      " 6   authorgender      2270 non-null   object \n",
      " 7   agewriting        1536 non-null   float64\n",
      " 8   agedeath          1525 non-null   float64\n",
      " 9   relMin            1870 non-null   object \n",
      " 10  nationalOrigin    2266 non-null   object \n",
      " 11  authorLocation    2270 non-null   object \n",
      " 12  U                 2076 non-null   object \n",
      " 13  M                 2076 non-null   object \n",
      " 14  S                 2076 non-null   object \n",
      " 15  F                 2076 non-null   object \n",
      " 16  L                 2076 non-null   object \n",
      " 17  text              2270 non-null   object \n",
      " 18  sequence          2270 non-null   int64  \n",
      " 19  scoreNeg          2270 non-null   float64\n",
      " 20  scorePos          2270 non-null   float64\n",
      " 21  scoreNeu          2270 non-null   float64\n",
      " 22  scoreCompound     2270 non-null   float64\n",
      " 23  totalTokens       2270 non-null   int64  \n",
      " 24  uniqueTokens      2270 non-null   int64  \n",
      " 25  lexicalDiversity  2270 non-null   float64\n",
      " 26  chunks            2270 non-null   int64  \n",
      " 27  position          2270 non-null   float64\n",
      " 28  topicNumber       2270 non-null   int64  \n",
      "dtypes: float64(10), int64(6), object(13)\n",
      "memory usage: 532.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Sentence Data\n",
    "df = pd.read_csv(\"20240411_PhD_Data4NER-LtrChk.csv\", index_col=0) \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the NER of various models on the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next few cells are run multiple times to check performance of various pre-trained models. \n",
    "# Do not run the this cell until after the first pass\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I started with 0 and checked \n",
    "chunk = 1349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Margaret Ellin is making a tart for Tea Willie is drawing on the slate Patty is crocheting Sarah is playing Eddie is playing with the cat and I am writing to you. Mama is trying to do without a servant now for they are more trouble than they are worth. You must excuse Mama's writing this mail as the gathering is on her forefinger of her right hand. Margaret Ellin and me have to carry on the correspondence. Yesterday was Grandmama Stretch's birthday and Mama said we might have a pudding for a treat. So Margaret Ellin made a currant dumpling and it was first rate. Besides it was her first attempt.\""
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place narratives into a list representing the corpus\n",
    "texts = df.text.values.tolist()\n",
    "texts[chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mentions: 8 \n",
      "\n",
      "{'Margaret Ellin': 3, 'Patty': 1, 'Sarah': 1, 'Eddie': 1, 'Mama': 2} \n",
      "\n",
      "Number of individuals: 5 \n",
      "\n",
      "Individuals: {'Sarah', 'Mama', 'Margaret Ellin', 'Patty', 'Eddie'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test on first item\n",
    "item = texts[chunk]\n",
    "\n",
    "# Run the language model on the 1st narrative\n",
    "narrative = nlp(item)\n",
    "\n",
    "# Find the mentions to people in the narrative\n",
    "\n",
    "for ent in narrative.ents:\n",
    "\n",
    "    mentions = [ent.text for ent in narrative.ents if ent.label_ == 'PERSON']\n",
    "        \n",
    "    counts = {}\n",
    "    for person in mentions:\n",
    "        counts[person] = counts.get(person, 0) + 1\n",
    "    \n",
    "    individuals = set(mentions)\n",
    "    \n",
    "print(\"Number of mentions:\", len(mentions), \"\\n\")\n",
    "print(counts, \"\\n\")    \n",
    "print(\"Number of individuals:\", len(individuals), \"\\n\")\n",
    "print(\"Individuals:\", individuals, \"\\n\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't great because Darling Sister Justina is being broken into two entities and others aren't being found (e.g., Eugénie de Guérin, Sister Blandina). Let's highlight the labels for a sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Margaret Ellin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is making a tart for Tea Willie is drawing on the slate \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Patty\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is crocheting \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sarah\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is playing \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Eddie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is playing with the cat and I am writing to you. Mama is trying to do without a servant now for they are more trouble than they are worth. You must excuse \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mama\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "'s writing this mail as the gathering is on her forefinger of her right hand. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Margaret Ellin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and me have to carry on the correspondence. Yesterday was Grandmama Stretch's birthday and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mama\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said we might have a pudding for a treat. So \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Margaret Ellin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " made a currant dumpling and it was first rate. Besides it was her first attempt.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = texts[chunk]\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"ent\", options = {\"ents\": [\"PERSON\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, only one of the two references to Mother Josephine is being labeled. Let's see if changing the model will help. For chunk 567, this performed well. For chunk 1135, this model reasonably well. It mis-identifies Snow as a person but that is because the work is capitalised. For 1703, this model is perfect. There are no named people. For 2269, this model is perfect. For 284, this model performed perfectly. For 851, this model misses Agnes, The Colonel, Tiny man (a nickname so understandable). Also, possible the Jessie is a boat rather than a person. However, given the number of person references, this model does reasonably well. For 1419, this model performs almost perfectly. It attaches \"more than L10\" to Robert's name for some reason. For 1988, this model is perfect. For 100, Sister Justina is missed and the Sister without a personal name is tagged erratically (sometimes, sometimes not).\n",
    "\n",
    "I'm attempting to use the 19th century Word2Vec langauge model (Hosseini, 2021). The files come as Gensim export formats .model and .npy. First, I had to load these into Gensim and then export a .txt file that I could use with Spacy. See notebook 20240412_histLM.ipynb for that step. Once I had the .txt file, I followed the steps described at https://www.youtube.com/watch?v=JmLQedi80_Y and https://github.com/wjbmattingly/spacy_custom_vectors/blob/main/spacy_word_vecs.ipynb. I have decided not to train the model on my text but rather use the pre-trained model. These are reflected in the notebook spacy_word_vecs in my home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load(\"/Users/alaynemoody/spacy_custom_vectors-main/models/01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not seem necessary but keeping just in case.\n",
    "#nlp.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = texts[chunk]\n",
    "#doc = nlp(text)\n",
    "#displacy.render(doc, style=\"ent\", options = {\"ents\": [\"PERSON\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is even worse because it's not capturing Sister Justin or Sister M Louis and is mixing up places (e.g, Mt St Vincent and Steuvenville). Let's try the large Spacy model. \n",
    "\n",
    "For chunk 567, this performed well. For chunk 1135, this one performs ok. It does not misidentify Snow but it does miss Mr Young, which orthographically is clearly a person. For 1703, this model is also perfect. For 2269, this model performs badly, missing Captain Hale but misinterpreting Character (capitalized for emphasis) as a person. For 284, this model does ok, catching John but also tagging Sister, which refers to the narrator. For 851, this model misses Dunbar, Agnes, the Colonel, the Tiny man, Duponts and Henry -- plus it tags the potential boat. All in all, this model performs poorly. For 1419, this model performs poorly, missing multiple referenecs to Crtichlow and Mr Davies as well as to Cundall. For 1988, this model is perfect. For 100, this model misses Sister Justina and erratically tags Sister without a surname. Also incorrectly tages \"Vd\" and so I'm calling it a poor performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Margaret Ellin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is making a tart for Tea Willie is drawing on the slate \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Patty\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is crocheting \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sarah\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is playing \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Eddie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is playing with the cat and I am writing to you. Mama is trying to do without a servant now for they are more trouble than they are worth. You must excuse Mama's writing this mail as the gathering is on her forefinger of her right hand. \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Margaret Ellin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and me have to carry on the correspondence. Yesterday was \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Grandmama Stretch's\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " birthday and Mama said we might have a pudding for a treat. So \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Margaret Ellin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " made a currant dumpling and it was first rate. Besides it was her first attempt.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#text = texts[chunk]\n",
    "#doc = nlp(text)\n",
    "#displacy.render(doc, style=\"ent\", options = {\"ents\": [\"PERSON\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't much better as the two Mother Josephine references are being treated as two different people, and Sister Justina and Sister Blandina are being missed. I am going to re-run the cells above of some more texts to see how we go. After 10 trials, the medium and large models were tied. Doing another 10 with just those two, focusing on the authors that tripped up the models most: Segale, Moodie, Harris (more concerned with Sarah than Harris because she has more letters in the corpus (see counts below).\n",
    "\n",
    "Additional Runs: For 567, this performed poorly because it identified DeWitt and Davenport as people when in fact the quotes indicate it is a company (probably a publishing house). For 1135, this model performs best -- skipping Snow and finding Young. For 1703, again perfect. For 2269, this model is perfect. For 284, this model is perfect. For 851, this model misses the Colonel, Mrs H Traill and the Tiny man, so the same number as the medium model -- reasonably well. For 1419, this model performs perfectly. For 1988, this model is perfect. For 100, this model it better about not tagging the Sister-sans-surname references but it incorrectly tags \"Por amor.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(df[df[\"docauthorid\"]==\"per0001043\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     484.000000\n",
       "mean      773.500000\n",
       "std       139.863028\n",
       "min       532.000000\n",
       "25%       652.750000\n",
       "50%       773.500000\n",
       "75%       894.250000\n",
       "max      1015.000000\n",
       "Name: docID-AT, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['docauthorname'][851]\n",
    "#df['docauthorname'][567]\n",
    "#len(df[df[\"docauthorname\"]==\"Moodie, Susannah Strickland, 1803-1885\"])\n",
    "#df['docID-AT'][df[\"docauthorname\"]==\"Moodie, Susannah Strickland, 1803-1885\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     261.000000\n",
       "mean     1271.260536\n",
       "std        86.756163\n",
       "min      1124.000000\n",
       "25%      1195.000000\n",
       "50%      1270.000000\n",
       "75%      1344.000000\n",
       "max      1422.000000\n",
       "Name: docID-AT, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['docauthorname'][1419]\n",
    "len(df[df[\"docauthorname\"]==\"Harris, Sarah Stretch, 1818-1897\"])\n",
    "#df['docID-AT'][df[\"docauthorname\"]==\"Harris, Sarah Stretch, 1818-1897\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['docauthorname'][1135]\n",
    "len(df[df[\"docauthorname\"]==\"Harris, Critchlow, 1813-1899\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After ten trials it became clear that the histLM performed by far worse than the two Spacy models and so I dropped it before continuing on with the final ten trials. The medium sized model slightly outperformed the large model (score of 2.4 compared to 2.5) and so I have decided to proceed with this one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named entity extraction for the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270\n",
      "2270\n",
      "2270\n",
      "5\n",
      "5\n",
      "{'Darling Sister': 1, 'Justina': 1, 'Sister M Louis': 1, \"Mother Josephine's\": 1, 'Mother Regina': 1}\n"
     ]
    }
   ],
   "source": [
    "mentsTot = [] \n",
    "mentsDis = []\n",
    "indsTot = []\n",
    "\n",
    "for item in texts:\n",
    "\n",
    "# Run the language model on the 1st narrative\n",
    "    narrative = nlp(item)\n",
    "\n",
    "# Find the mentions to people in the narrative\n",
    "\n",
    "    for ent in narrative.ents:\n",
    "\n",
    "        mentions = [ent.text for ent in narrative.ents if ent.label_ == 'PERSON']\n",
    "        \n",
    "        counts = {}\n",
    "        for person in mentions:\n",
    "            counts[person] = counts.get(person, 0) + 1\n",
    "    \n",
    "        individuals = set(mentions)\n",
    "    \n",
    "    mentsTot.append(len(mentions))\n",
    "    mentsDis.append(counts)\n",
    "    indsTot.append(len(individuals))\n",
    "    \n",
    "                   \n",
    "print(len(mentsTot)) \n",
    "print(len(indsTot))\n",
    "print(len(mentsDis))\n",
    "\n",
    "print(mentsTot[0]) \n",
    "print(indsTot[0])\n",
    "print(mentsDis[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for 1st person singular pronounds, subjective and objective only per Tackman, A. M., Sbarra, D. A., Carey, A. L., Donnellan, M. B., Horn, A. B., Holtzman, N. S., Edwards, T. S., Pennebaker, J. W., & Mehl, M. R. (2019). Depression, Negative Emotionality, and Self-Referential Language: A Multi-Lab, Multi-Measure, and Multi-Language-Task Research Synthesis. Journal of Personality and Social Psychology, 116(5), 817–834. https://doi.org/10.1037/pspp0000187.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I ', \"I'm \", \"I've \", \"I'll \", \"I'd \", ' me ', 'Me ', ' myself ', 'Myself ']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounAll = [\"I \", \n",
    "               \"I'm \", \n",
    "               \"I've \", \n",
    "               \"I'll \", \n",
    "               \"I'd \", \n",
    "               \" me \", \n",
    "               \"Me \", \n",
    "               \" myself \", \n",
    "               \"Myself \"]\n",
    "pronounAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I ', \"I'm \", \"I've \", \"I'll \", \"I'd \"]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounSub = [\"I \", \"I'm \", \"I've \", \"I'll \", \"I'd \"]\n",
    "pronounSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' me ', 'Me ', ' myself ', 'Myself ']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pronounObj = [\" me \", \n",
    "               \"Me \", \n",
    "               \" myself \", \n",
    "               \"Myself \"]\n",
    "pronounObj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts = [x.lower() for x in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'magnitized by them. The expression of her face is sad even to melancholy but sweetly feminine. I do not believe that the raps are produced by spirits that have been of this world but I cannot believe that she with her pure spiritual face is capable of deceiving. She certainly does not procure these mysterious sounds by foot or hand and though I cannot help thinking that they emanate from her mind and that she is herself the spirit I believe she is perfectly unconscious of it herself. But to make you understand more about it I had better describe the scene first prefacing it with my being a great sceptic on the subject and therefore as a consequence of my doubts anxious to investigate it to the bottom. Miss Fox has near relatives in this place to whom Mr Moodie had expressed a wish to see the fair Kate should she again visit our town. One morning about three weeks since I was alone in the drawing room when my servant girl announced Miss F and her cousin. I had seen her the summer before for a few minutes in the street and was so much charmed with her face and her manners that it was with pleasure I met her again. After some conversation on the subject of the raps she said ‘Would you like to hear them.’ I said ‘yes very much indeed as it would confirm or do away with my doubts.’ She then asked the spirits if they would communicate with Mrs M which being'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Subjective\n",
    "\n",
    "Count = 0\n",
    "\n",
    "for i in pronounSub:\n",
    "    Count = texts[chunk].count(i) + Count\n",
    "\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Objective\n",
    "\n",
    "Count = 0\n",
    "\n",
    "for i in pronounObj:\n",
    "    Count = texts[chunk].count(i) + Count\n",
    "\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# All pronouns\n",
    "\n",
    "Count = 0\n",
    "\n",
    "for i in pronounAll:\n",
    "    Count = texts[chunk].count(i) + Count\n",
    "\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now run on all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270\n",
      "[10, 16, 16, 20, 15, 18, 14, 24, 22]\n"
     ]
    }
   ],
   "source": [
    "# Now the rest\n",
    "\n",
    "fppAll_Ct = []\n",
    "\n",
    "for item in texts:\n",
    "    Count = 0\n",
    "    for i in pronounAll:\n",
    "        #print(texts[0].count(i))\n",
    "        Count = item.count(i) + Count\n",
    "    \n",
    "    fppAll_Ct.append(Count)\n",
    "\n",
    "print(len(fppAll_Ct))\n",
    "print(fppAll_Ct[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270\n",
      "[9, 13, 13, 18, 11, 13, 12, 20, 14]\n"
     ]
    }
   ],
   "source": [
    "# Now just subjective pronouns\n",
    "\n",
    "fppSub_Ct = []\n",
    "\n",
    "for item in texts:\n",
    "    Count = 0\n",
    "    for i in pronounSub:\n",
    "        #print(texts[0].count(i))\n",
    "        Count = item.count(i) + Count\n",
    "    \n",
    "    fppSub_Ct.append(Count)\n",
    "\n",
    "print(len(fppSub_Ct))\n",
    "print(fppSub_Ct[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2270\n",
      "[1, 3, 3, 2, 4, 5, 2, 4, 8]\n"
     ]
    }
   ],
   "source": [
    "# Now just subjective pronouns\n",
    "\n",
    "fppObj_Ct = []\n",
    "\n",
    "for item in texts:\n",
    "    Count = 0\n",
    "    for i in pronounObj:\n",
    "        #print(texts[0].count(i))\n",
    "        Count = item.count(i) + Count\n",
    "    \n",
    "    fppObj_Ct.append(Count)\n",
    "\n",
    "print(len(fppObj_Ct))\n",
    "print(fppObj_Ct[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new variables to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2270 entries, 0 to 2269\n",
      "Data columns (total 35 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   docID-AT          2270 non-null   int64  \n",
      " 1   docauthorid       2270 non-null   object \n",
      " 2   docauthorname     2270 non-null   object \n",
      " 3   docid             2270 non-null   object \n",
      " 4   docyear           2235 non-null   float64\n",
      " 5   docmonth          2171 non-null   float64\n",
      " 6   authorgender      2270 non-null   object \n",
      " 7   agewriting        1536 non-null   float64\n",
      " 8   agedeath          1525 non-null   float64\n",
      " 9   relMin            1870 non-null   object \n",
      " 10  nationalOrigin    2266 non-null   object \n",
      " 11  authorLocation    2270 non-null   object \n",
      " 12  U                 2076 non-null   object \n",
      " 13  M                 2076 non-null   object \n",
      " 14  S                 2076 non-null   object \n",
      " 15  F                 2076 non-null   object \n",
      " 16  L                 2076 non-null   object \n",
      " 17  text              2270 non-null   object \n",
      " 18  sequence          2270 non-null   int64  \n",
      " 19  scoreNeg          2270 non-null   float64\n",
      " 20  scorePos          2270 non-null   float64\n",
      " 21  scoreNeu          2270 non-null   float64\n",
      " 22  scoreCompound     2270 non-null   float64\n",
      " 23  totalTokens       2270 non-null   int64  \n",
      " 24  uniqueTokens      2270 non-null   int64  \n",
      " 25  lexicalDiversity  2270 non-null   float64\n",
      " 26  chunks            2270 non-null   int64  \n",
      " 27  position          2270 non-null   float64\n",
      " 28  topicNumber       2270 non-null   int64  \n",
      " 29  mentsDis          2270 non-null   object \n",
      " 30  mentsTot          2270 non-null   int64  \n",
      " 31  indsTot           2270 non-null   int64  \n",
      " 32  fppAll_Ct         2270 non-null   int64  \n",
      " 33  fppSub_Ct         2270 non-null   int64  \n",
      " 34  fppObj_Ct         2270 non-null   int64  \n",
      "dtypes: float64(10), int64(11), object(14)\n",
      "memory usage: 638.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df['mentsDis'] = [', '.join(x) for x in mentsDis]\n",
    "df['mentsTot'] = mentsTot\n",
    "df['indsTot'] = indsTot\n",
    "df['fppAll_Ct'] = fppAll_Ct\n",
    "df['fppSub_Ct'] = fppSub_Ct\n",
    "df['fppObj_Ct'] = fppObj_Ct\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID-AT</th>\n",
       "      <th>docauthorid</th>\n",
       "      <th>docauthorname</th>\n",
       "      <th>docid</th>\n",
       "      <th>docyear</th>\n",
       "      <th>docmonth</th>\n",
       "      <th>authorgender</th>\n",
       "      <th>agewriting</th>\n",
       "      <th>agedeath</th>\n",
       "      <th>relMin</th>\n",
       "      <th>...</th>\n",
       "      <th>lexicalDiversity</th>\n",
       "      <th>chunks</th>\n",
       "      <th>position</th>\n",
       "      <th>topicNumber</th>\n",
       "      <th>mentsDis</th>\n",
       "      <th>mentsTot</th>\n",
       "      <th>indsTot</th>\n",
       "      <th>fppAll_Ct</th>\n",
       "      <th>fppSub_Ct</th>\n",
       "      <th>fppObj_Ct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>per0001043</td>\n",
       "      <td>Segale, Sister Blandina, 1850-1941</td>\n",
       "      <td>S1019-D002</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>22.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>12</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>7</td>\n",
       "      <td>Darling Sister, Justina, Sister M Louis, Mothe...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>per0001043</td>\n",
       "      <td>Segale, Sister Blandina, 1850-1941</td>\n",
       "      <td>S1019-D002</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>22.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>12</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>10</td>\n",
       "      <td>Tait, McCann</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>per0001043</td>\n",
       "      <td>Segale, Sister Blandina, 1850-1941</td>\n",
       "      <td>S1019-D002</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>22.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>12</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>per0001043</td>\n",
       "      <td>Segale, Sister Blandina, 1850-1941</td>\n",
       "      <td>S1019-D002</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>22.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610108</td>\n",
       "      <td>12</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>21</td>\n",
       "      <td>Sister Anthony, Bigelow</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>per0001043</td>\n",
       "      <td>Segale, Sister Blandina, 1850-1941</td>\n",
       "      <td>S1019-D002</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>F</td>\n",
       "      <td>22.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590226</td>\n",
       "      <td>12</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>21</td>\n",
       "      <td>Sister Anthony, McCabe, Segale, Henry, Seminar...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   docID-AT docauthorid                       docauthorname       docid  \\\n",
       "0         1  per0001043  Segale, Sister Blandina, 1850-1941  S1019-D002   \n",
       "1         2  per0001043  Segale, Sister Blandina, 1850-1941  S1019-D002   \n",
       "2         3  per0001043  Segale, Sister Blandina, 1850-1941  S1019-D002   \n",
       "3         4  per0001043  Segale, Sister Blandina, 1850-1941  S1019-D002   \n",
       "4         5  per0001043  Segale, Sister Blandina, 1850-1941  S1019-D002   \n",
       "\n",
       "   docyear  docmonth authorgender  agewriting  agedeath relMin  ...  \\\n",
       "0   1872.0      11.0            F        22.0      91.0   True  ...   \n",
       "1   1872.0      11.0            F        22.0      91.0   True  ...   \n",
       "2   1872.0      11.0            F        22.0      91.0   True  ...   \n",
       "3   1872.0      11.0            F        22.0      91.0   True  ...   \n",
       "4   1872.0      11.0            F        22.0      91.0   True  ...   \n",
       "\n",
       "  lexicalDiversity chunks  position topicNumber  \\\n",
       "0         0.634146     12  0.083333           7   \n",
       "1         0.619231     12  0.166667          10   \n",
       "2         0.621212     12  0.250000          10   \n",
       "3         0.610108     12  0.333333          21   \n",
       "4         0.590226     12  0.416667          21   \n",
       "\n",
       "                                            mentsDis mentsTot indsTot  \\\n",
       "0  Darling Sister, Justina, Sister M Louis, Mothe...        5       5   \n",
       "1                                       Tait, McCann        2       2   \n",
       "2                                                           0       0   \n",
       "3                            Sister Anthony, Bigelow        3       2   \n",
       "4  Sister Anthony, McCabe, Segale, Henry, Seminar...        7       7   \n",
       "\n",
       "  fppAll_Ct  fppSub_Ct  fppObj_Ct  \n",
       "0        10          9          1  \n",
       "1        16         13          3  \n",
       "2        16         13          3  \n",
       "3        20         18          2  \n",
       "4        15         11          4  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"20240414_PhD_FinalData-LtrChk.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
