{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge topic labels to chunk dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gensim\n",
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmanized text\n",
    "with open(\"20240701_PhD_AltDiaChkLem-N.txt\", \"rb\") as fp:   # Unpickling\n",
    "    data_lemmatized = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = models.ldamodel.LdaModel.load('20240701_PhD_TopicDiaChkMAL10a5i25o13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not needed because I converted from Mallet to LDA in 20240331_PhD_TopicLetterChkNV-Mallet\n",
    "# Load saved mallet\n",
    "# lda_mallet = gensim.models.wrappers.LdaMallet.load(\"20240221_PhD_TopicChkMAL14\")\n",
    "# Convert to LDA\n",
    "# ldamodel = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(lda_mallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.130*\"dinner\" + 0.128*\"tea\" + 0.061*\"breakfast\" + 0.039*\"bath\" + '\n",
      "  '0.034*\"bread\" + 0.029*\"clothe\" + 0.023*\"washing\" + 0.021*\"cake\" + '\n",
      "  '0.019*\"lot\" + 0.019*\"fish\" + 0.017*\"meat\" + 0.015*\"job\" + 0.012*\"pain\" + '\n",
      "  '0.011*\"beach\" + 0.010*\"milk\" + 0.009*\"bird\" + 0.009*\"goat\" + 0.009*\"mutton\" '\n",
      "  '+ 0.008*\"potato\" + 0.008*\"garden\"'),\n",
      " (1,\n",
      "  '0.090*\"town\" + 0.080*\"port\" + 0.058*\"pound\" + 0.044*\"train\" + 0.028*\"mill\" '\n",
      "  '+ 0.026*\"church\" + 0.022*\"meeting\" + 0.021*\"land\" + 0.015*\"ship\" + '\n",
      "  '0.014*\"account\" + 0.014*\"wife\" + 0.012*\"doctor\" + 0.011*\"board\" + '\n",
      "  '0.009*\"college\" + 0.009*\"school\" + 0.008*\"arrangement\" + 0.008*\"steamer\" + '\n",
      "  '0.008*\"bower\" + 0.008*\"committee\" + 0.007*\"purchase\"'),\n",
      " (2,\n",
      "  '0.086*\"letter\" + 0.048*\"wheat\" + 0.034*\"flour\" + 0.031*\"club\" + '\n",
      "  '0.027*\"wife\" + 0.022*\"office\" + 0.022*\"bank\" + 0.018*\"pound\" + '\n",
      "  '0.017*\"party\" + 0.016*\"price\" + 0.015*\"ton\" + 0.015*\"paper\" + 0.014*\"sale\" '\n",
      "  '+ 0.013*\"whist\" + 0.012*\"share\" + 0.012*\"news\" + 0.011*\"lunched\" + '\n",
      "  '0.011*\"affair\" + 0.011*\"railway\" + 0.011*\"order\"'),\n",
      " (3,\n",
      "  '0.057*\"home\" + 0.039*\"walk\" + 0.033*\"dress\" + 0.025*\"drive\" + '\n",
      "  '0.024*\"garden\" + 0.023*\"talk\" + 0.019*\"child\" + 0.019*\"row\" + 0.015*\"call\" '\n",
      "  '+ 0.014*\"flower\" + 0.014*\"friend\" + 0.014*\"poll\" + 0.013*\"ride\" + '\n",
      "  '0.013*\"mama\" + 0.012*\"glass\" + 0.012*\"door\" + 0.010*\"finish\" + '\n",
      "  '0.009*\"plant\" + 0.009*\"mind\" + 0.008*\"read\"'),\n",
      " (4,\n",
      "  '0.114*\"home\" + 0.050*\"work\" + 0.031*\"truck\" + 0.028*\"boat\" + 0.021*\"wood\" + '\n",
      "  '0.018*\"game\" + 0.018*\"aunt\" + 0.018*\"gun\" + 0.017*\"side\" + 0.017*\"deal\" + '\n",
      "  '0.016*\"mill\" + 0.015*\"chapel\" + 0.014*\"dog\" + 0.013*\"beach\" + 0.012*\"book\" '\n",
      "  '+ 0.012*\"river\" + 0.011*\"place\" + 0.011*\"water\" + 0.010*\"rate\" + '\n",
      "  '0.010*\"duck\"'),\n",
      " (5,\n",
      "  '0.086*\"weather\" + 0.078*\"rain\" + 0.052*\"wind\" + 0.049*\"dinner\" + '\n",
      "  '0.026*\"thing\" + 0.021*\"black\" + 0.021*\"vessel\" + 0.019*\"store\" + '\n",
      "  '0.018*\"bay\" + 0.017*\"cooking\" + 0.014*\"shower\" + 0.014*\"dust\" + '\n",
      "  '0.014*\"mail\" + 0.013*\"trip\" + 0.013*\"thunder\" + 0.013*\"sea\" + 0.012*\"lot\" + '\n",
      "  '0.012*\"showery\" + 0.011*\"change\" + 0.011*\"point\"'),\n",
      " (6,\n",
      "  '0.041*\"man\" + 0.040*\"people\" + 0.038*\"horse\" + 0.037*\"place\" + '\n",
      "  '0.030*\"station\" + 0.026*\"road\" + 0.026*\"home\" + 0.022*\"house\" + '\n",
      "  '0.020*\"trouble\" + 0.020*\"girl\" + 0.018*\"woman\" + 0.017*\"lunch\" + '\n",
      "  '0.016*\"mother\" + 0.014*\"family\" + 0.014*\"wash\" + 0.012*\"police\" + '\n",
      "  '0.012*\"drink\" + 0.011*\"baby\" + 0.010*\"leave\" + 0.010*\"friend\"'),\n",
      " (7,\n",
      "  '0.059*\"house\" + 0.027*\"question\" + 0.026*\"motion\" + 0.026*\"govt\" + '\n",
      "  '0.023*\"office\" + 0.022*\"club\" + 0.018*\"cabinet\" + 0.015*\"treasurer\" + '\n",
      "  '0.014*\"matter\" + 0.014*\"member\" + 0.013*\"return\" + 0.012*\"vote\" + '\n",
      "  '0.011*\"genl\" + 0.011*\"report\" + 0.010*\"speech\" + 0.010*\"view\" + '\n",
      "  '0.009*\"case\" + 0.009*\"debate\" + 0.009*\"business\" + 0.009*\"governor\"'),\n",
      " (8,\n",
      "  '0.095*\"horse\" + 0.058*\"boy\" + 0.051*\"water\" + 0.042*\"fire\" + 0.036*\"thing\" '\n",
      "  '+ 0.032*\"buggy\" + 0.028*\"head\" + 0.024*\"sand\" + 0.024*\"hand\" + '\n",
      "  '0.024*\"sheep\" + 0.018*\"start\" + 0.015*\"supper\" + 0.013*\"tank\" + '\n",
      "  '0.011*\"black\" + 0.011*\"camp\" + 0.010*\"feed\" + 0.010*\"scrub\" + 0.009*\"mare\" '\n",
      "  '+ 0.009*\"road\" + 0.009*\"chop\"'),\n",
      " (9,\n",
      "  '0.127*\"bed\" + 0.047*\"room\" + 0.045*\"sleep\" + 0.041*\"mail\" + 0.041*\"child\" + '\n",
      "  '0.037*\"breakfast\" + 0.036*\"work\" + 0.021*\"rest\" + 0.017*\"kitchen\" + '\n",
      "  '0.017*\"cook\" + 0.015*\"fear\" + 0.012*\"arm\" + 0.012*\"heat\" + 0.012*\"bedroom\" '\n",
      "  '+ 0.012*\"floor\" + 0.011*\"lubra\" + 0.011*\"bottle\" + 0.010*\"heart\" + '\n",
      "  '0.010*\"care\" + 0.009*\"pair\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(sorted(ldamodel.print_topics(num_words=20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1023 entries, 0 to 1022\n",
      "Data columns (total 30 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   docID-AT          1023 non-null   int64  \n",
      " 1   docid             1023 non-null   object \n",
      " 2   docyear           1023 non-null   int64  \n",
      " 3   docmonth          0 non-null      float64\n",
      " 4   authorName        1023 non-null   object \n",
      " 5   docauthorid       1023 non-null   object \n",
      " 6   authorLocation    1023 non-null   object \n",
      " 7   authorGender      1023 non-null   object \n",
      " 8   nationalOrigin    921 non-null    object \n",
      " 9   irish             921 non-null    object \n",
      " 10  otherUK           921 non-null    object \n",
      " 11  relMin            1023 non-null   bool   \n",
      " 12  catholic          1023 non-null   bool   \n",
      " 13  otherChristian    1023 non-null   bool   \n",
      " 14  U                 1023 non-null   bool   \n",
      " 15  M                 1023 non-null   bool   \n",
      " 16  S                 1023 non-null   bool   \n",
      " 17  F                 1023 non-null   bool   \n",
      " 18  L                 1023 non-null   bool   \n",
      " 19  text              1023 non-null   object \n",
      " 20  sequence          1023 non-null   int64  \n",
      " 21  totalTokens       1023 non-null   int64  \n",
      " 22  uniqueTokens      1023 non-null   int64  \n",
      " 23  lexicalDiversity  1023 non-null   float64\n",
      " 24  scoreNeg          1023 non-null   float64\n",
      " 25  scoreNeu          1023 non-null   float64\n",
      " 26  scorePos          1023 non-null   float64\n",
      " 27  scoreCom          1023 non-null   float64\n",
      " 28  chunks            1023 non-null   int64  \n",
      " 29  position          1023 non-null   float64\n",
      "dtypes: bool(8), float64(7), int64(6), object(9)\n",
      "memory usage: 183.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Metadata\n",
    "df = pd.read_csv(\"20240701_PhD_Data4TopicModel-DiaryChunk.csv\") \n",
    "df = df.rename(columns={'Unnamed: 0':'docID-AT'})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.text.values.tolist()\n",
    "# data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Functions & Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics(ldamodel=ldamodel, corpus=corpus, texts=texts):\n",
    "    # Init output\n",
    "    topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num, topn=20)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                topics_df = topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    topics_df = pd.concat([topics_df, contents], axis=1)\n",
    "    return(topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>horse, boy, water, fire, thing, buggy, head, s...</td>\n",
       "      <td>Charra Wednesday Nov 4th 1883 A nice cool day ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2587</td>\n",
       "      <td>horse, boy, water, fire, thing, buggy, head, s...</td>\n",
       "      <td>night so that I can't get up in the morning ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2568</td>\n",
       "      <td>horse, boy, water, fire, thing, buggy, head, s...</td>\n",
       "      <td>Frank did not arrive till 2P.M so after he had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>horse, boy, water, fire, thing, buggy, head, s...</td>\n",
       "      <td>to Camp caused it. Mrs Roberts lent me two pai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3044</td>\n",
       "      <td>horse, boy, water, fire, thing, buggy, head, s...</td>\n",
       "      <td>which I can't understand but hope to know toni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0               8              0.2199   \n",
       "1            1               8              0.2587   \n",
       "2            2               8              0.2568   \n",
       "3            3               8              0.1785   \n",
       "4            4               8              0.3044   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  horse, boy, water, fire, thing, buggy, head, s...   \n",
       "1  horse, boy, water, fire, thing, buggy, head, s...   \n",
       "2  horse, boy, water, fire, thing, buggy, head, s...   \n",
       "3  horse, boy, water, fire, thing, buggy, head, s...   \n",
       "4  horse, boy, water, fire, thing, buggy, head, s...   \n",
       "\n",
       "                                                Text  \n",
       "0  Charra Wednesday Nov 4th 1883 A nice cool day ...  \n",
       "1  night so that I can't get up in the morning ha...  \n",
       "2  Frank did not arrive till 2P.M so after he had...  \n",
       "3  to Camp caused it. Mrs Roberts lent me two pai...  \n",
       "4  which I can't understand but hope to know toni...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the topic for the first 10 rows. \n",
    "df_topic_keywords = format_topics(ldamodel=ldamodel, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_Text_topicNumber = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(data):\n",
    "    topic_dist = ldamodel.get_document_topics(corpus[index])\n",
    "\n",
    "    # topic_dist is a list of tuples: each tuple has a topic number with its corresponding proportion\n",
    "    sorted_topic_dist = sorted(topic_dist, key=lambda x: (x[1]), reverse=True) # Sort it in descending order\n",
    "    \n",
    "    # Pick the top one:\n",
    "    topic_number = sorted_topic_dist[0][0]\n",
    "    map_Text_topicNumber[item] = topic_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first key value pair in dictionary (text, label)\n",
    "# dict(list(map_Text_topicNumber.items())[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>docauthorid</th>\n",
       "      <th>text</th>\n",
       "      <th>topicNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>Charra Wednesday Nov 4th 1883 A nice cool day ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>night so that I can't get up in the morning ha...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>Frank did not arrive till 2P.M so after he had...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>to Camp caused it. Mrs Roberts lent me two pai...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>which I can't understand but hope to know toni...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>his stores Friday and Saturday at Laura Bay. t...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>could hardly keep up had dinner Mrs Roberts ki...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>all the work Frank let out her traces then Bil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>to drive me if he wanted to catch the Vessel a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>Wenyss came in and gave me the offer of horses...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D0002</td>\n",
       "      <td>D0002</td>\n",
       "      <td>two messages on Friday night for me to go down...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    docid docauthorid                                               text  \\\n",
       "0   D0002       D0002  Charra Wednesday Nov 4th 1883 A nice cool day ...   \n",
       "1   D0002       D0002  night so that I can't get up in the morning ha...   \n",
       "2   D0002       D0002  Frank did not arrive till 2P.M so after he had...   \n",
       "3   D0002       D0002  to Camp caused it. Mrs Roberts lent me two pai...   \n",
       "4   D0002       D0002  which I can't understand but hope to know toni...   \n",
       "5   D0002       D0002  his stores Friday and Saturday at Laura Bay. t...   \n",
       "6   D0002       D0002  could hardly keep up had dinner Mrs Roberts ki...   \n",
       "7   D0002       D0002  all the work Frank let out her traces then Bil...   \n",
       "8   D0002       D0002  to drive me if he wanted to catch the Vessel a...   \n",
       "9   D0002       D0002  Wenyss came in and gave me the offer of horses...   \n",
       "10  D0002       D0002  two messages on Friday night for me to go down...   \n",
       "\n",
       "    topicNumber  \n",
       "0             8  \n",
       "1             8  \n",
       "2             8  \n",
       "3             8  \n",
       "4             8  \n",
       "5             8  \n",
       "6             5  \n",
       "7             0  \n",
       "8             0  \n",
       "9             0  \n",
       "10            8  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topicNumber'] = df['text'].map(map_Text_topicNumber)\n",
    "df.loc[:10,['docid', 'docauthorid', 'text', 'topicNumber']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>dinner, tea, breakfast, bath, bread, clothe, w...</td>\n",
       "      <td>no use laying in bed pretting about it so jump...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>town, port, pound, train, mill, church, meetin...</td>\n",
       "      <td>the long delayed dividend of  pounds 153. 9. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>letter, wheat, flour, club, wife, office, bank...</td>\n",
       "      <td>after some discussion we agreed to put in a te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3697</td>\n",
       "      <td>home, walk, dress, drive, garden, talk, child,...</td>\n",
       "      <td>hack and am now going to read Macanll tor an h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.4256</td>\n",
       "      <td>home, work, truck, boat, wood, game, aunt, gun...</td>\n",
       "      <td>A nice day I went to the jetty there are 6 Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>weather, rain, wind, dinner, thing, black, ves...</td>\n",
       "      <td>came in with us and stayed the day we had some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.3821</td>\n",
       "      <td>man, people, horse, place, station, road, home...</td>\n",
       "      <td>the grown with the Campbells every one very ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>house, question, motion, govt, office, club, c...</td>\n",
       "      <td>House A long question of priviledges raised on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.4399</td>\n",
       "      <td>horse, boy, water, fire, thing, buggy, head, s...</td>\n",
       "      <td>hot day we were up by 5.30am but for the horse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>bed, room, sleep, mail, child, breakfast, work...</td>\n",
       "      <td>and was groaning and rolling About for hours M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0          0              0.3701   \n",
       "1          1              0.4180   \n",
       "2          2              0.4167   \n",
       "3          3              0.3697   \n",
       "4          4              0.4256   \n",
       "5          5              0.3060   \n",
       "6          6              0.3821   \n",
       "7          7              0.5183   \n",
       "8          8              0.4399   \n",
       "9          9              0.3766   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  dinner, tea, breakfast, bath, bread, clothe, w...   \n",
       "1  town, port, pound, train, mill, church, meetin...   \n",
       "2  letter, wheat, flour, club, wife, office, bank...   \n",
       "3  home, walk, dress, drive, garden, talk, child,...   \n",
       "4  home, work, truck, boat, wood, game, aunt, gun...   \n",
       "5  weather, rain, wind, dinner, thing, black, ves...   \n",
       "6  man, people, horse, place, station, road, home...   \n",
       "7  house, question, motion, govt, office, club, c...   \n",
       "8  horse, boy, water, fire, thing, buggy, head, s...   \n",
       "9  bed, room, sleep, mail, child, breakfast, work...   \n",
       "\n",
       "                                                Text  \n",
       "0  no use laying in bed pretting about it so jump...  \n",
       "1  the long delayed dividend of  pounds 153. 9. T...  \n",
       "2  after some discussion we agreed to put in a te...  \n",
       "3  hack and am now going to read Macanll tor an h...  \n",
       "4  A nice day I went to the jetty there are 6 Ste...  \n",
       "5  came in with us and stayed the day we had some...  \n",
       "6  the grown with the Campbells every one very ki...  \n",
       "7  House A long question of priviledges raised on...  \n",
       "8  hot day we were up by 5.30am but for the horse...  \n",
       "9  and was groaning and rolling About for hours M...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "topics_outdf_grpd = df_topic_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in topics_outdf_grpd:\n",
    "    topics_sorteddf_mallet = pd.concat([topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "topics_sorteddf_mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    144\n",
       "0    135\n",
       "1    111\n",
       "7    109\n",
       "4    107\n",
       "2    100\n",
       "8     93\n",
       "6     89\n",
       "5     71\n",
       "9     64\n",
       "Name: Dominant_Topic, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_keywords['Dominant_Topic'].value_counts()\n",
    "topic_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.1408\n",
       "0    0.1320\n",
       "1    0.1085\n",
       "7    0.1065\n",
       "4    0.1046\n",
       "2    0.0978\n",
       "8    0.0909\n",
       "6    0.0870\n",
       "5    0.0694\n",
       "9    0.0626\n",
       "Name: Dominant_Topic, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "topic_contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>dinner, tea, breakfast, bath, bread, clothe, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1</td>\n",
       "      <td>town, port, pound, train, mill, church, meetin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>2</td>\n",
       "      <td>letter, wheat, flour, club, wife, office, bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>home, walk, dress, drive, garden, talk, child,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>4</td>\n",
       "      <td>home, work, truck, boat, wood, game, aunt, gun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>weather, rain, wind, dinner, thing, black, ves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>man, people, horse, place, station, road, home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>7</td>\n",
       "      <td>house, question, motion, govt, office, club, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>horse, boy, water, fire, thing, buggy, head, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9</td>\n",
       "      <td>bed, room, sleep, mail, child, breakfast, work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dominant_Topic                                     Topic_Keywords\n",
       "7                 0  dinner, tea, breakfast, bath, bread, clothe, w...\n",
       "549               1  town, port, pound, train, mill, church, meetin...\n",
       "566               2  letter, wheat, flour, club, wife, office, bank...\n",
       "33                3  home, walk, dress, drive, garden, talk, child,...\n",
       "90                4  home, work, truck, boat, wood, game, aunt, gun...\n",
       "6                 5  weather, rain, wind, dinner, thing, black, ves...\n",
       "25                6  man, people, horse, place, station, road, home...\n",
       "562               7  house, question, motion, govt, office, club, c...\n",
       "0                 8  horse, boy, water, fire, thing, buggy, head, s...\n",
       "30                9  bed, room, sleep, mail, child, breakfast, work..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_keywords[['Dominant_Topic', 'Topic_Keywords']].drop_duplicates().sort_values(by = 'Dominant_Topic')\n",
    "topic_num_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dinner, tea, breakfast, bath, bread, clothe, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>town, port, pound, train, mill, church, meetin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>letter, wheat, flour, club, wife, office, bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>home, walk, dress, drive, garden, talk, child,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>home, work, truck, boat, wood, game, aunt, gun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>weather, rain, wind, dinner, thing, black, ves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>man, people, horse, place, station, road, home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>house, question, motion, govt, office, club, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>horse, boy, water, fire, thing, buggy, head, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>bed, room, sleep, mail, child, breakfast, work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dominant_Topic                                     Topic_Keywords\n",
       "0               0  dinner, tea, breakfast, bath, bread, clothe, w...\n",
       "1               1  town, port, pound, train, mill, church, meetin...\n",
       "2               2  letter, wheat, flour, club, wife, office, bank...\n",
       "3               3  home, walk, dress, drive, garden, talk, child,...\n",
       "4               4  home, work, truck, boat, wood, game, aunt, gun...\n",
       "5               5  weather, rain, wind, dinner, thing, black, ves...\n",
       "6               6  man, people, horse, place, station, road, home...\n",
       "7               7  house, question, motion, govt, office, club, c...\n",
       "8               8  horse, boy, water, fire, thing, buggy, head, s...\n",
       "9               9  bed, room, sleep, mail, child, breakfast, work..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_num_keywords.reset_index(drop=True, inplace=True)\n",
    "topic_num_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering\n",
    "# topic_num_keywords = topic_num_keywords.reindex([11,17,14,5,3,2,4,0,18,20,7,1,15,10,16,19,9,6,8,12,13])\n",
    "# topic_num_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>counts</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dinner, tea, breakfast, bath, bread, clothe, w...</td>\n",
       "      <td>135</td>\n",
       "      <td>0.1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>town, port, pound, train, mill, church, meetin...</td>\n",
       "      <td>111</td>\n",
       "      <td>0.1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>letter, wheat, flour, club, wife, office, bank...</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>home, walk, dress, drive, garden, talk, child,...</td>\n",
       "      <td>144</td>\n",
       "      <td>0.1408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>home, work, truck, boat, wood, game, aunt, gun...</td>\n",
       "      <td>107</td>\n",
       "      <td>0.1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>weather, rain, wind, dinner, thing, black, ves...</td>\n",
       "      <td>71</td>\n",
       "      <td>0.0694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>man, people, horse, place, station, road, home...</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>house, question, motion, govt, office, club, c...</td>\n",
       "      <td>109</td>\n",
       "      <td>0.1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>horse, boy, water, fire, thing, buggy, head, s...</td>\n",
       "      <td>93</td>\n",
       "      <td>0.0909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>bed, room, sleep, mail, child, breakfast, work...</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dominant_Topic                                     Topic_Keywords  counts  \\\n",
       "0               0  dinner, tea, breakfast, bath, bread, clothe, w...     135   \n",
       "1               1  town, port, pound, train, mill, church, meetin...     111   \n",
       "2               2  letter, wheat, flour, club, wife, office, bank...     100   \n",
       "3               3  home, walk, dress, drive, garden, talk, child,...     144   \n",
       "4               4  home, work, truck, boat, wood, game, aunt, gun...     107   \n",
       "5               5  weather, rain, wind, dinner, thing, black, ves...      71   \n",
       "6               6  man, people, horse, place, station, road, home...      89   \n",
       "7               7  house, question, motion, govt, office, club, c...     109   \n",
       "8               8  horse, boy, water, fire, thing, buggy, head, s...      93   \n",
       "9               9  bed, room, sleep, mail, child, breakfast, work...      64   \n",
       "\n",
       "   contribution  \n",
       "0        0.1320  \n",
       "1        0.1085  \n",
       "2        0.0978  \n",
       "3        0.1408  \n",
       "4        0.1046  \n",
       "5        0.0694  \n",
       "6        0.0870  \n",
       "7        0.1065  \n",
       "8        0.0909  \n",
       "9        0.0626  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts.rename('counts'), topic_contribution.rename('contribution')], axis=1).sort_values(by = 'Dominant_Topic')\n",
    "df_dominant_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topics.to_csv(\"20240701_PhD_TopicsDiaChkMAL10a5i25o13.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1023 entries, 0 to 1022\n",
      "Data columns (total 31 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   docID-AT          1023 non-null   int64  \n",
      " 1   docid             1023 non-null   object \n",
      " 2   docyear           1023 non-null   int64  \n",
      " 3   docmonth          0 non-null      float64\n",
      " 4   authorName        1023 non-null   object \n",
      " 5   docauthorid       1023 non-null   object \n",
      " 6   authorLocation    1023 non-null   object \n",
      " 7   authorGender      1023 non-null   object \n",
      " 8   nationalOrigin    921 non-null    object \n",
      " 9   irish             921 non-null    object \n",
      " 10  otherUK           921 non-null    object \n",
      " 11  relMin            1023 non-null   bool   \n",
      " 12  catholic          1023 non-null   bool   \n",
      " 13  otherChristian    1023 non-null   bool   \n",
      " 14  U                 1023 non-null   bool   \n",
      " 15  M                 1023 non-null   bool   \n",
      " 16  S                 1023 non-null   bool   \n",
      " 17  F                 1023 non-null   bool   \n",
      " 18  L                 1023 non-null   bool   \n",
      " 19  text              1023 non-null   object \n",
      " 20  sequence          1023 non-null   int64  \n",
      " 21  totalTokens       1023 non-null   int64  \n",
      " 22  uniqueTokens      1023 non-null   int64  \n",
      " 23  lexicalDiversity  1023 non-null   float64\n",
      " 24  scoreNeg          1023 non-null   float64\n",
      " 25  scoreNeu          1023 non-null   float64\n",
      " 26  scorePos          1023 non-null   float64\n",
      " 27  scoreCom          1023 non-null   float64\n",
      " 28  chunks            1023 non-null   int64  \n",
      " 29  position          1023 non-null   float64\n",
      " 30  topicNumber       1023 non-null   int64  \n",
      "dtypes: bool(8), float64(7), int64(7), object(9)\n",
      "memory usage: 191.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"20240701_PhD_Data4NER-DiaChk.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
