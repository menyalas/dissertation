{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Scores: Diaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "sentenceTokenizer = nltk.data.load('tokenizers/punkt/english.pickle') #Load tokenizer\n",
    "sentimentAnalyzer = SentimentIntensityAnalyzer() #Initialize sentiment scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7268"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentimentAnalyzer.lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = PlaintextCorpusReader('test', '.*txt') #Define corpus\n",
    "len(Corpus.fileids()) #How many files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a new folder called \"cleaned\" in the letters folder for the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building / testing the text cleaning script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Charra\"\n",
      "Wednesday Nov 4th 1883 A nice cool \n",
      "day Mrs Roberts + I were talking nearly \n",
      "the whole night feel very tired today\n",
      "Tom left just after breakfast for\n",
      " Mr Hiern's Station he will not be back\n",
      " until Sunday or Monday, he is talking\n",
      " of going out to the new Tanks over\n",
      " 100 miles from here if he can make \n",
      "sure of getting water I Darned up the\n",
      " socks, + Stockings, I had with me + cut\n",
      " out some under clothes.\n",
      "\"Charra\"\n",
      " Thursday Nov 8th North wind\n",
      "first thing this morning with heavy\n",
      "thunder but only a few drops of rain,\n",
      "I was so sleepy did not get up till\n",
      "very late had been hand sewing which\n",
      "is very tiresome My throat keep very sore\n",
      "still the Cold has not nearly left one\n",
      "Worrier ill with cold our Black Boy\n",
      "\"Charra\"\n",
      "Friday Nov 9th We have had thunder\n",
      "+ lightning with a little rain off + on all\n",
      "day I have been sewing all day but Mrs\n",
      "Roberts keeps me talking after going to bed\n",
      "till all hours of the night so that I can't get\n",
      "up in the morning, have had a head ache all\n",
      "day from want of rest + sitting too close. Young\n",
      "Jeff Miller + Jimmy Roberts here tonight they\n",
      "are on the road to \"Mercaney\" with sheep\n",
      "what a torment Mrs Roberts is to the Children\n",
      "she rubbed grease on a plate then smoked\n",
      "\n",
      "it black over a Candle + marked the Boys\n",
      "faces after they were asleep, drinking so \n",
      "much tea kills me I must leave it off\n",
      "Charra\n",
      "Saturday nov 10th We had more rain +\n",
      " thun\n"
     ]
    }
   ],
   "source": [
    "text = open(\"test/D0002.txt\", \"r\")\n",
    "#text = open(\"test/test.txt\", \"r\")\n",
    "#text = open(\"test/D0002_periods.txt\", \"r\")\n",
    "#text = open(\"20240628_PhD_Diaries/cleaned/D0002.txt\", \"r\")\n",
    "text = text.read()\n",
    "#text = text[:1374]\n",
    "#text = text.split('9th weather')[0]\n",
    "print(text[:1374])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charra Wednesday Nov 4th 1883 A nice cool day Mrs Roberts and I were talking nearly the whole night feel very tired today Tom left just after breakfast for Mr Hiern's Station he will not be back until Sunday or Monday, he is talking of going out to the new Tanks over 100 miles from here if he can make sure of getting water I Darned up the socks, and Stockings, I had with me and cut out some under clothes. Charra Thursday Nov 8th North wind first thing this morning with heavy thunder but only a few drops of rain, I was so sleepy did not get up till very late had been hand sewing which is very tiresome My throat keep very sore still the Cold has not nearly left one Worrier ill with cold our Black Boy Charra Friday Nov 9th We have had thunder and lightning with a little rain off and on all day I have been sewing all day but Mrs Roberts keeps me talking after going to bed till all hours of the night so that I can't get up in the morning, have had a head ache all day from want of rest and sitting too close. Young Jeff Miller and Jimmy Roberts here tonight they are on the road to Mercaney with sheep what a torment Mrs Roberts is to the Children she rubbed grease on a plate then smoked it black over a Candle and marked the Boys faces after they were asleep, drinking so much tea kills me I must leave it off Charra Saturday nov 10th We had more rain and thunder\n"
     ]
    }
   ],
   "source": [
    "text = re.sub(r\"(\\n+)\",\" \", text) # Replace blank lines with a single space\n",
    "text = re.sub(r\"(\\[[^?]*?\\])\",\"\", text) #Remove bracketed (i.e., transcriber) notes\n",
    "text = re.sub(r\"(\\[)\",\"\", text) #Remove opening bracket\n",
    "text = re.sub(r\"(\\?\\])\",\"\", text) #Remove question mark and closing bracket\n",
    "text = re.sub(r\"(—){2,}\",\" \", text) # Replace 2 or more dashes with space\n",
    "text = re.sub(r\"(-){2,}\",\" \", text) # Replace 2 or more hyphens with space\n",
    "text = re.sub(r\"(&dot)\",\"\", text) # Remove this expression (a dot)\n",
    "text = re.sub(r\"(_)\",\"\", text) # Remove underscore\n",
    "#text = re.sub(r\"([Â,Ã])\",\"\", text) # Remove special characters ORIGINAL\n",
    "text = re.sub(r\"([Ã])\",\"\", text) # Remove special character REVISED\n",
    "text = re.sub(r\"([Â])\",\"\", text) # Remove special character REVISED\n",
    "text = re.sub(r\"(£)\",\" pounds \", text) # Replace pound symbol with word\n",
    "text = re.sub(r\"( & )\",\" and \", text) # Replace ampersand with word\n",
    "text = re.sub(r\"(\\r)\",\" \", text) # Replace /r with blank space\n",
    "text = re.sub(r\"(\\˙)\",\"\", text) # Remove dot\n",
    "text = re.sub(r\"(\\#PAGE)\",\"\", text) #Remove #Page\n",
    "text = re.sub(r\"(\\(sic\\))\",\"\", text) #Remove #sic\n",
    "text = re.sub(r\"(\\. ){2,}\",\"\", text) # Remove ellipses\n",
    "text = re.sub(r\"(\\/)\",\"\", text) # Remove backslash\n",
    "text = re.sub(r\"(^\\s*)\",\"\", text) # Remove blank spaces at the start of the string\n",
    "text = re.sub(r\"(\\s){2,}\",\" \", text) # Replace 2 or more white spaces with just one\n",
    "text = re.sub(r\"$\",\"\\n\", text) # Ensure that there is a newline to the end of the string\n",
    "text = re.sub(r\"(\\+)\",\"and\", text) # Replace blank lines with a single space\n",
    "text = re.sub(r\"(\\\\)\",\"\", text) #Remove opening slash\n",
    "text = re.sub(r\"(\\/)\",\"\", text) #Remove closing slash thus leaving contents\n",
    "text = re.sub(r\"(₤)\",\" pounds \", text) # Replace lira symbol with word pounds\n",
    "text = re.sub(r\"(\\\")\",\"\", text) # Quotation marks\n",
    "print(text[:1374])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Charra Wednesday Nov 4th 1883 A nice cool day Mrs Roberts and I were talking nearly the whole night feel very tired today Tom left just after breakfast for Mr Hiern's Station he will not be back until Sunday or Monday, he is talking of going out to the new Tanks over 100 miles from here if he can make sure of getting water I Darned up the socks, and Stockings, I had with me and cut out some under clothes.\",\n",
       " \"Charra Thursday Nov 8th North wind first thing this morning with heavy thunder but only a few drops of rain, I was so sleepy did not get up till very late had been hand sewing which is very tiresome My throat keep very sore still the Cold has not nearly left one Worrier ill with cold our Black Boy Charra Friday Nov 9th We have had thunder and lightning with a little rain off and on all day I have been sewing all day but Mrs Roberts keeps me talking after going to bed till all hours of the night so that I can't get up in the morning, have had a head ache all day from want of rest and sitting too close.\",\n",
       " 'Young Jeff Miller and Jimmy Roberts here tonight they are on the road to Mercaney with sheep what a torment Mrs Roberts is to the Children she rubbed grease on a plate then smoked it black over a Candle and marked the Boys faces after they were asleep, drinking so much tea kills me I must leave it off Charra Saturday nov 10th We had more rain and thunder this morning I was late up again Mrs Roberts will think me a sleepy head the breakfast was over when I came out the Boys were away and Mr Roberts just leaving Mrs Roberts and the girls Cleaning, and Cooking, I was sewing We were just in the middle of a fine old gossip when Frank was seen coming with two Police horses one packed with Toms uniform he has to go to Venus Bay for Drill, by the sixteenth of the month which is next Friday Frank, did not arrive till 2P.M so after he had some dinner I thought it best to come on to Denial Bay if we did not meet Tom coming to Charra and wait till Sunday morning feeling sure we should meet him about 10am at Denial Bay it was after three P.M. when we started and had 26 miles to travel over heavy sand for some miles the last part of the Journey and by the sea coast.',\n",
       " 'it was quite dark when we reached the Tanks we were all very cold the Boys watered and turned out the horses lit the fire boiled the quart pots and made tea I had no appetite feeling worried for I feared the mare would not bring us on she looked so bad, then we made a bed under the shed of bags of Chaff which belong to the government Frank lay down by my side we did not undress.',\n",
       " 'I did not take off my boots the Boys slept well but I did not had flatulence and palpatation very badly I think taking a little Brandy on coming to Camp caused it.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = sentenceTokenizer.tokenize(text)\n",
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now calculate sentiment for the whole folder and the medium Vader lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docid</th>\n",
       "      <th>totalTokens</th>\n",
       "      <th>uniqueTokens</th>\n",
       "      <th>lexicalDiversity</th>\n",
       "      <th>scoreNeg</th>\n",
       "      <th>scoreNeu</th>\n",
       "      <th>scorePos</th>\n",
       "      <th>scoreCom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, docid, totalTokens, uniqueTokens, lexicalDiversity, scoreNeg, scoreNeu, scorePos, scoreCom]\n",
       "Index: []"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = pd.DataFrame(columns = ['text','docid', 'totalTokens', 'uniqueTokens', 'lexicalDiversity', 'scoreNeg', 'scoreNeu', 'scorePos', 'scoreCom']) # Create a new dataframe to hold sentences, letter id and compound scores\n",
    "sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus = PlaintextCorpusReader('test', '.*txt') #Define corpus\n",
    "len(Corpus.fileids()) #How many files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D0002_periods.txt\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "for fileid in Corpus.fileids(): # For each file in the corpus\n",
    "    #Proprocess and save text\n",
    "    f = open(\"test/cleaned/\" + fileid, \"w\", encoding='utf-8')\n",
    "    text = Corpus.raw(fileid) # Place the string into the object \"text\"\n",
    "    text = re.sub(r\"(\\n+)\",\" \", text) # Replace blank lines with a single space\n",
    "    text = re.sub(r\"(\\[[^?]*?\\])\",\"\", text) #Remove bracketed (i.e., transcriber) notes\n",
    "    text = re.sub(r\"(\\[)\",\"\", text) #Remove opening bracket\n",
    "    text = re.sub(r\"(\\?\\])\",\"\", text) #Remove question mark and closing bracket\n",
    "    text = re.sub(r\"(—){2,}\",\" \", text) # Replace 2 or more dashes with space\n",
    "    text = re.sub(r\"(-){2,}\",\" \", text) # Replace 2 or more hyphens with space\n",
    "    text = re.sub(r\"(&dot)\",\"\", text) # Remove this expression (a dot)\n",
    "    text = re.sub(r\"(_)\",\"\", text) # Remove underscore\n",
    "    text = re.sub(r\"([Ã])\",\"\", text) # Remove special character\n",
    "    text = re.sub(r\"([Â])\",\"\", text) # Remove special character\n",
    "    text = re.sub(r\"(£)\",\" pounds \", text) # Replace pound symbol with word\n",
    "    text = re.sub(r\"( & )\",\" and \", text) # Replace ampersand with word\n",
    "    text = re.sub(r\"(\\r)\",\" \", text) # Replace /r with blank space\n",
    "    text = re.sub(r\"(\\˙)\",\"\", text) # Remove dot\n",
    "    text = re.sub(r\"(\\#PAGE)\",\"\", text) #Remove #Page\n",
    "    text = re.sub(r\"(\\(sic\\))\",\"\", text) #Remove #sic\n",
    "    text = re.sub(r\"(\\. ){2,}\",\"\", text) # Remove ellipses\n",
    "    text = re.sub(r\"(\\/)\",\"\", text) # Remove backslash\n",
    "    text = re.sub(r\"(^\\s*)\",\"\", text) # Remove blank spaces at the start of the string\n",
    "    text = re.sub(r\"(\\s){2,}\",\" \", text) # Replace 2 or more white spaces with just one\n",
    "    text = re.sub(r\"$\",\"\\n\", text) # Ensure that there is a newline to the end of the string\n",
    "    text = re.sub(r\"(\\+)\",\"and\", text) # Replace blank lines with a single space\n",
    "    text = re.sub(r\"(\\\\)\",\"\", text) #Remove opening slash\n",
    "    text = re.sub(r\"(\\/)\",\"\", text) #Remove closing slash thus leaving contents\n",
    "    text = re.sub(r\"(₤)\",\" pounds \", text) # Replace lira symbol with word pounds\n",
    "    text = re.sub(r\"(\\\")\",\"\", text) # Quotation marks\n",
    "    text = re.sub(r\"$\",\"\\n\", text) # Ensure that there is a newline to the end of the string\n",
    "    f.write(text)\n",
    "    f.close()\n",
    "    # Now basic metrics\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    totalTokens = len(tokens)\n",
    "    uniqueTokens = len(set(tokens))\n",
    "    lexicalDiversity = uniqueTokens/totalTokens\n",
    "    # Now score sentiment\n",
    "    sentences = sentenceTokenizer.tokenize(text) # Place sentences into a list called \"sentences\"\n",
    "    scoreNeg = 0.0\n",
    "    scoreNeu = 0.0\n",
    "    scorePos = 0.0\n",
    "    scoreCom = 0.0\n",
    "    #sequence = 0 # Create a counter to keep track of sentence order\n",
    "    for sentence in sentences: # For each sentence in the letter \n",
    "        #sequence +=1 # Counter updater\n",
    "        scores = sentimentAnalyzer.polarity_scores(sentence) # Calculate sentiment scores\n",
    "        scoreNeg += scores[\"neg\"]\n",
    "        scoreNeu += scores[\"neu\"]\n",
    "        scorePos += scores[\"pos\"]\n",
    "        scoreCom += scores[\"compound\"]\n",
    "    scoreNeg = scoreNeg / len(sentences)\n",
    "    scoreNeu = scoreNeu / len(sentences)\n",
    "    scorePos = scorePos / len(sentences)\n",
    "    scoreCom = scoreCom / len(sentences)\n",
    "    new_row = pd.Series([text, fileid, totalTokens, uniqueTokens, lexicalDiversity, scoreNeg, scoreNeu, scorePos, scoreCom], index=['text','docid', 'totalTokens', 'uniqueTokens', 'lexicalDiversity', 'scoreNeg', 'scoreNeu', 'scorePos', 'scoreCom'])\n",
    "    sentiment = pd.concat([sentiment, new_row.to_frame().T], ignore_index=True)\n",
    "    print(fileid) # Show progress\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docid</th>\n",
       "      <th>totalTokens</th>\n",
       "      <th>uniqueTokens</th>\n",
       "      <th>lexicalDiversity</th>\n",
       "      <th>scoreNeg</th>\n",
       "      <th>scoreNeu</th>\n",
       "      <th>scorePos</th>\n",
       "      <th>scoreCom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charra Wednesday Nov 4th 1883. A nice cool day...</td>\n",
       "      <td>D0002_periods.txt</td>\n",
       "      <td>14055</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.136322</td>\n",
       "      <td>0.052131</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>0.051171</td>\n",
       "      <td>-0.012982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              docid  \\\n",
       "0  Charra Wednesday Nov 4th 1883. A nice cool day...  D0002_periods.txt   \n",
       "\n",
       "  totalTokens uniqueTokens lexicalDiversity  scoreNeg  scoreNeu  scorePos  \\\n",
       "0       14055         1916         0.136322  0.052131  0.896698  0.051171   \n",
       "\n",
       "   scoreCom  \n",
       "0 -0.012982  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>docid</th>\n",
       "      <th>totalTokens</th>\n",
       "      <th>uniqueTokens</th>\n",
       "      <th>lexicalDiversity</th>\n",
       "      <th>scoreNeg</th>\n",
       "      <th>scoreNeu</th>\n",
       "      <th>scorePos</th>\n",
       "      <th>scoreCom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charra Wednesday Nov 4th 1883 A nice cool day ...</td>\n",
       "      <td>D0002</td>\n",
       "      <td>81551</td>\n",
       "      <td>6885</td>\n",
       "      <td>0.084426</td>\n",
       "      <td>0.057039</td>\n",
       "      <td>0.893670</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>-0.178757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 6th Very wet morning it has stopped me fro...</td>\n",
       "      <td>D0003</td>\n",
       "      <td>19635</td>\n",
       "      <td>1939</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>0.028140</td>\n",
       "      <td>0.916614</td>\n",
       "      <td>0.053863</td>\n",
       "      <td>0.070318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diary of Capt. John Hart 1865 1 January 1 Sund...</td>\n",
       "      <td>D0007</td>\n",
       "      <td>54919</td>\n",
       "      <td>6332</td>\n",
       "      <td>0.115297</td>\n",
       "      <td>0.050477</td>\n",
       "      <td>0.896772</td>\n",
       "      <td>0.052744</td>\n",
       "      <td>-0.017036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edith Gwynne July 14 71 Glynde Place July 17 B...</td>\n",
       "      <td>D0009</td>\n",
       "      <td>28146</td>\n",
       "      <td>5644</td>\n",
       "      <td>0.200526</td>\n",
       "      <td>0.039007</td>\n",
       "      <td>0.910292</td>\n",
       "      <td>0.050688</td>\n",
       "      <td>0.025624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  docid  totalTokens  \\\n",
       "0  Charra Wednesday Nov 4th 1883 A nice cool day ...  D0002        81551   \n",
       "1  May 6th Very wet morning it has stopped me fro...  D0003        19635   \n",
       "2  Diary of Capt. John Hart 1865 1 January 1 Sund...  D0007        54919   \n",
       "3  Edith Gwynne July 14 71 Glynde Place July 17 B...  D0009        28146   \n",
       "\n",
       "   uniqueTokens  lexicalDiversity  scoreNeg  scoreNeu  scorePos  scoreCom  \n",
       "0          6885          0.084426  0.057039  0.893670  0.049316 -0.178757  \n",
       "1          1939          0.098752  0.028140  0.916614  0.053863  0.070318  \n",
       "2          6332          0.115297  0.050477  0.896772  0.052744 -0.017036  \n",
       "3          5644          0.200526  0.039007  0.910292  0.050688  0.025624  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the .txt from the file name\n",
    "sentiment['docid'] = sentiment['docid'].str.replace(r'.txt', '', regex=True)\n",
    "sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
